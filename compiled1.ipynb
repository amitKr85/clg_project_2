{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "import string\n",
    "punctuations = list(string.punctuation)\n",
    "stop = stop + punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ModPosTag(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def simple_clean(words):\n",
    "#     output_words = [w.lower() for w in words if not w.lower() in stop]\n",
    "#     return output_words\n",
    "\n",
    "def simple_clean(words):\n",
    "    output_words = [w for w in words if not w in stop]\n",
    "    return output_words\n",
    "\n",
    "\n",
    "# def complex_clean(words):\n",
    "#     output_words = []\n",
    "#     for w in words:\n",
    "#         if w.lower() not in stop:\n",
    "#             pos = pos_tag([w])\n",
    "#             clean_w = lemmatizer.lemmatize(w, pos = ModPosTag(pos[0][1]))\n",
    "#             output_words.append(clean_w.lower())\n",
    "#     return output_words\n",
    "\n",
    "# remove lemetize\n",
    "def complex_clean(words):\n",
    "    output_words = []\n",
    "    for w in words:\n",
    "        if w not in stop:\n",
    "            pos = pos_tag([w])\n",
    "            clean_w = lemmatizer.lemmatize(w, pos = ModPosTag(pos[0][1]))\n",
    "            output_words.append(clean_w)\n",
    "    return output_words\n",
    "\n",
    "\n",
    "def read_words(words_dir):\n",
    "\n",
    "    files = [os.path.join(words_dir, fi) for fi in os.listdir(words_dir)]\n",
    "\n",
    "    #features_matrix = np.zeros((len(files), 3000))\n",
    "    docID = 0;\n",
    "    all_words = []\n",
    "    all_words_heading = []\n",
    "    major_words_abstract = []\n",
    "    for fil in files:\n",
    "        with open(fil) as fi:\n",
    "            words_abstract = []\n",
    "            for i, line in enumerate(fi):\n",
    "                if (i == 0):\n",
    "                    temp = line.split()\n",
    "                    temp1 = simple_clean(temp)\n",
    "                    \n",
    "                    words_abstract += temp1\n",
    "                    all_words_heading += temp1\n",
    "                else:\n",
    "                    temp = line.split()\n",
    "                    temp1 = complex_clean(temp)\n",
    "                    print(fil)\n",
    "                    print()\n",
    "                    print(temp1)\n",
    "                    words_abstract += temp1\n",
    "                    all_words += temp1\n",
    "\n",
    "            major_words_abstract.append(words_abstract)\n",
    "            len(all_words)\n",
    "    return major_words_abstract, all_words, all_words_heading\n",
    "\n",
    "def tag_updater(df, variable_code):\n",
    "    for key, values in variable_code.items():\n",
    "        temp = str(key)\n",
    "        area = variable_code[key]\n",
    "        for val in area:\n",
    "            df.at[val-1, temp] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_tags(words_dir):\n",
    "    files = [os.path.join(words_dir, fi) for fi in os.listdir(words_dir)]\n",
    "\n",
    "    # features_matrix = np.zeros((len(files), 3000))\n",
    "    docID = 0;\n",
    "    tagss = set()\n",
    "    for fil in files:\n",
    "        docID+=1\n",
    "        with open(fil) as fi:\n",
    "            for i, line in enumerate(fi):\n",
    "                temp = line.split(',')\n",
    "                tagss.update(temp)\n",
    "    return docID, tagss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = {}\n",
    "\n",
    "def read_files(words_directory, tags_directory):\n",
    "\n",
    "    wo = [os.path.join(words_directory, wi) for wi in os.listdir(words_directory)]\n",
    "    ta = [os.path.join(tags_directory, ti) for ti in os.listdir(tags_directory)]\n",
    "    ctr=0\n",
    "    for (ab, t) in zip(wo, ta):\n",
    "        ctr +=1\n",
    "        with open(t) as su:\n",
    "            for i, line in enumerate(su):\n",
    "                tag = line.split(',')\n",
    "                for q in tag:\n",
    "                    if q not in mydict:\n",
    "                        mydict[q] = []\n",
    "                    mydict[q].append(ctr)\n",
    "\n",
    "    return mydict,ctr\n",
    "\n",
    "def extract_features(Words, features):\n",
    "    feature_matrix = np.zeros((len(Words), len(features)))\n",
    "    docID = 0\n",
    "    for doc in Words:\n",
    "        for word in doc:\n",
    "            for i in range(len(features)):\n",
    "                if features[i] == word:\n",
    "                    wordID = i\n",
    "                    feature_matrix[docID, wordID] += 1\n",
    "        docID = docID + 1\n",
    "    np.shape(feature_matrix)\n",
    "    print(feature_matrix)\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\1.txt\n",
      "\n",
      "['There', 'many', 'study', 'researcher', 'attempt', 'classify', 'student', 'attentiveness.', 'Many', 'approach', 'depend', 'qualitative', 'analysis', 'lack', 'quantitative', 'analysis.', 'Therefore,', 'work', 'focus', 'bridging', 'gap', 'qualitative', 'quantitative', 'approach', 'classify', 'student', 'attentiveness.', 'Thus,', 'research', 'applies', 'machine', 'learn', 'algorithm', '(K-means', 'SVM)', 'automatically', 'classify', 'student', 'attentive', 'inattentive', 'use', 'data', 'consumer', 'RGB-D', 'sensor.', 'Results', 'research', 'use', 'improve', 'teach', 'strategy', 'instructor', 'level', 'aid', 'instructor', 'implement', 'personalize', 'learn', 'systems,', 'National', 'Academy', 'Engineering', 'Grand', 'Challenge.', 'This', 'research', 'applies', 'machine', 'learn', 'algorithm', 'educational', 'setting.', 'Data', 'algorithm', 'use', 'instructor', 'provide', 'valuable', 'feedback', 'effectiveness', 'instructional', 'strategy', 'pedagogies.', 'Instructors', 'use', 'feedback', 'improve', 'instructional', 'strategies,', 'student', 'benefit', 'achieve', 'improve', 'learn', 'subject', 'mastery.', 'Ultimately,', 'result', \"students'\", 'increase', 'ability', 'work', 'respective', 'areas.', 'Broadly,', 'work', 'help', 'advance', 'effort', 'many', 'area', 'education', 'instruction.', 'It', 'expect', 'improve', 'instructional', 'strategy', 'implement', 'personalize', 'learn', 'help', 'create', 'competent,', 'capable,', 'prepared', 'person', 'available', 'future', 'workforce.']\n",
      "abstract\\10.txt\n",
      "\n",
      "['To', 'assure', 'cyber', 'security', 'enterprise,', 'typically', 'SIEM', '(Security', 'Information', 'Event', 'Management)', 'system', 'place', 'normalize', 'security', 'event', 'different', 'preventive', 'technology', 'flag', 'alerts.', 'Analysts', 'security', 'operation', 'center', '(SOC)', 'investigate', 'alert', 'decide', 'truly', 'malicious', 'not.', 'However,', 'generally', 'number', 'alert', 'overwhelm', 'majority', 'false', 'positive', 'exceed', \"SOC's\", 'capacity', 'handle', 'alerts.', 'Because', 'this,', 'potential', 'malicious', 'attack', 'compromise', 'host', 'may', 'missed.', 'Machine', 'learn', 'viable', 'approach', 'reduce', 'false', 'positive', 'rate', 'improve', 'productivity', 'SOC', 'analysts.', 'In', 'paper,', 'develop', 'user-centric', 'machine', 'learn', 'framework', 'cyber', 'security', 'operation', 'center', 'real', 'enterprise', 'environment.', 'We', 'discus', 'typical', 'data', 'source', 'SOC,', 'work', 'flow,', 'leverage', 'process', 'data', 'set', 'build', 'effective', 'machine', 'learn', 'system.', 'The', 'paper', 'target', 'towards', 'two', 'group', 'readers.', 'The', 'first', 'group', 'data', 'scientist', 'machine', 'learn', 'researcher', 'cyber', 'security', 'domain', 'knowledge', 'want', 'build', 'machine', 'learn', 'system', 'security', 'operation', 'center.', 'The', 'second', 'group', 'audience', 'cyber', 'security', 'practitioner', 'deep', 'knowledge', 'expertise', 'cyber', 'security,', 'machine', 'learn', 'experience', 'wish', 'build', 'one', 'themselves.', 'Throughout', 'paper,', 'use', 'system', 'built', 'Symantec', 'SOC', 'production', 'environment', 'example', 'demonstrate', 'complete', 'step', 'data', 'collection,', 'label', 'creation,', 'feature', 'engineering,', 'machine', 'learn', 'algorithm', 'selection,', 'model', 'performance', 'evaluations,', 'risk', 'score', 'generation.']\n",
      "abstract\\11.txt\n",
      "\n",
      "['Recent', 'development', 'information', 'system', 'well', 'computerization', 'business', 'process', 'organization', 'lead', 'faster,', 'easy', 'accurate', 'data', 'analysis.', 'Data', 'mining', 'machine', 'learn', 'technique', 'use', 'increasingly', 'analysis', 'data', 'various', 'field', 'range', 'medicine', 'finance,', 'education', 'energy', 'applications.', 'Machine', 'learn', 'technique', 'make', 'possible', 'deduct', 'meaningful', 'information', 'data', 'process', 'data', 'mining.', 'Such', 'meaningful', 'significant', 'information', 'help', 'organization', 'establish', 'future', 'policy', 'sounder', 'basis,', 'gain', 'major', 'advantage', 'term', 'time', 'cost.', 'This', 'study', 'applies', 'classification', 'algorithm', 'use', 'data', 'mining', 'machine', 'learn', 'technique', 'data', 'obtain', 'individual', 'vocational', 'guidance', 'process,', 'try', 'determine', 'appropriate', 'algorithm.']\n",
      "abstract\\12.txt\n",
      "\n",
      "['Establishing', 'fatigue', 'crack', 'propagation', 'rate', 'key', 'forecasting', 'structure', 'fatigue', 'lifetime,', 'nine', 'parameter', 'fatigue', 'crack', 'propagation', 'rate', 'model', 'McEvily', 'model', 'widely', 'apply', 'present,', 'complex', 'realize', 'models,', 'partial', 'derivative', 'must', 'calculate', 'large', 'deviation', 'fit', 'static', 'parameter', 'actual', 'value', 'physical', 'conception', 'clear.', 'In', 'accordance', 'disadvantage', 'methods,', 'Based', 'optimum', 'parameter', 'selection', 'grid', 'search', 'cross', 'validation,', 'present', 'optimal', 'common', 'machine', 'learn', 'algorithm', '(least', 'square', 'support', 'vector', 'machine-LSSVM)', 'method', 'fatigue', 'crack', 'propagation', 'rate', 'forecast.', 'Complicated', 'strong', 'nonlinear', 'fatigue', 'crack', 'propagation', 'rate', 'curve', 'simulated', 'network', 'design', 'conformation', 'LSSVM', 'learn', 'algorithm', 'optimize', 'SVM', 'parameter', 'select', 'method', 'network', 'search', 'cross', 'validation.', 'Compared', 'error', 'output', 'value', 'optimize', 'model', 'output', 'value', 'nine', 'parameter', 'fatigue', 'crack', 'propagation', 'rate', 'fitting', 'model,', 'LSSVM', 'whose', 'parameter', 'optimize', 'cross', 'validation', 'excellent', 'ability', 'nonlinear', 'model', 'generalization.', 'It', 'provide', 'simple', 'feasible', 'intelligent', 'approach', 'material', 'fatigue', 'analysis.']\n",
      "abstract\\13.txt\n",
      "\n",
      "['With', 'rapid', 'development', 'e-commerce,', 'financial', 'data', 'mining', 'one', 'important', 'research', 'topic', 'data', 'mining', 'community.', 'Support', 'vector', 'machine', '(SVMs)', 'ensemble', 'learn', 'two', 'popular', 'technique', 'machine', 'learn', 'field.', 'In', 'paper,', 'support', 'vector', 'machine', 'ensemble', 'learn', 'use', 'classify', 'financial', 'data', 'respectively.', 'The', 'experiment', 'conduct', 'public', 'dataset', 'show', 'compare', 'SVMs,', 'ensemble', 'learn', 'achieves', 'obvious', 'improvement', 'performance.']\n",
      "abstract\\14.txt\n",
      "\n",
      "['Incremental', 'learn', 'technique', 'possible', 'solution', 'handle', 'vast', 'data', 'information', 'Internet', 'update', 'get', 'faster.', 'Support', 'vector', 'machine', 'work', 'well', 'incremental', 'learn', 'model', 'impressive', 'performance', 'outstanding', 'power', 'summarize', 'data', 'space', 'concise', 'way.', 'This', 'paper', 'proposes', 'heuristic', 'algorithm', 'incremental', 'learn', 'SVM', 'take', 'possible', 'impact', 'new', 'training', 'data', 'history', 'data', 'account.', 'The', 'idea', 'heuristic', 'algorithm', 'partition', 'difference', 'set', 'less', 'elements,', 'exist', 'hyperplane', 'much', 'closer', 'optimal', 'one.', 'New', 'support', 'vector', 'algorithm', 'consist', 'exist', 'support', 'vector', 'partition', 'difference', 'set', 'new', 'training', 'data', 'history', 'data', 'separate', 'hyperplane.', 'The', 'algorithm', 'improves', 'classification', 'precision', 'add', 'partition', 'difference', 'set,', 'decrease', 'computation', 'complexity', 'construct', 'new', 'classification', 'hyperplane', 'support', 'vector', 'set.', 'The', 'experimental', 'result', 'show', 'heuristic', 'algorithm', 'efficient', 'effective', 'improve', 'classification', 'precision.']\n",
      "abstract\\15.txt\n",
      "\n",
      "['IASS', 'integrate', 'anti-spam', 'system,', 'adopts', 'machine', 'learn', 'filter', 'spam', 'intelligent,', 'flexible,', 'precise,', 'self-adaptive', 'way.', 'The', 'method', 'linear', 'classification', 'base', 'optimal', 'separate', 'hyperplane', 'K-means', 'cluster', 'use', 'action', 'recognition', 'layer.', 'The', 'method', 'improve', 'naive', 'Bayes', 'use', 'content', 'analysis', 'layer.', 'The', 'application', 'machine', 'learn', 'help', 'improve', 'performance', 'IASS.']\n",
      "abstract\\16.txt\n",
      "\n",
      "['Single', 'machine', 'schedule', 'method', 'attract', 'lot', 'attention', 'recent', 'years.', 'Most', 'dynamic', 'single', 'machine', 'schedule', 'problem', 'practice', 'address', 'use', 'dispatch', 'rules.', 'However,', 'single', 'dispatch', 'rule', 'found', 'perform', 'well', 'important', 'criteria,', 'rule', 'take', 'account', 'status', 'resource', \"system's\", 'environment.', 'In', 'research,', 'intelligent', 'agent-based', 'single', 'machine', 'schedule', 'system', 'proposed,', 'agent', 'train', 'new', 'improve', 'Q-learning', 'algorithm.', 'In', 'schedule', 'system,', 'agent', 'selects', 'one', 'appropriate', 'dispatch', 'rule', 'machine', 'base', 'available', 'information.', 'The', 'agent', 'train', 'new', 'simulated', 'annealing-based', 'Q-learning', 'algorithm.', 'The', 'simulation', 'result', 'show', 'simulated', 'annealing-based', 'Q-learning', 'agent', 'able', 'learn', 'select', 'best', 'dispatch', 'rule', 'different', 'system', 'objectives.', 'The', 'result', 'also', 'indicate', 'simulated', 'annealing-based', 'Q-learning', 'agent', 'could', 'perform', 'well', 'criteria,', 'impossible', 'use', 'one', 'dispatch', 'rule', 'independently.']\n",
      "abstract\\17.txt\n",
      "\n",
      "['How', 'define', 'architecture', 'classifier', 'dynamically', 'one', 'major', 'research', 'topic', 'online', 'learning.', 'This', 'paper', 'present', 'new', 'online', 'learn', 'algorithm', 'Radial', 'Basis', 'Function', 'Network', 'name', 'Sensitivity', 'Based', 'Neurons', 'Growing', 'Pruning', 'Method', 'RBF', 'network', '(SBGAP).', 'The', 'performance', 'SBGAP', 'evaluate', 'experimentally', 'compare', 'accuracy', 'number', 'neuron', 'exist', 'methods.', 'The', 'experimental', 'result', 'show', 'SBGAP', 'achieve', 'litter', 'high', 'accuracy', 'few', 'hidden', 'unit', 'situations.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\18.txt\n",
      "\n",
      "['This', 'paper', 'proposes', 'new', 'fuzzy', 'multicategory', 'support', 'vector', 'machine', '(FMSVM)', 'classifier.', 'The', 'main', 'idea', 'propose', 'FMSVM', 'us', 'knowledge', 'ambiguity', 'associate', 'membership', 'sample', 'give', 'class', 'relative', 'location', 'sample', 'origin.', 'Compared', 'exist', 'SVMs,', 'new', 'propose', 'FMSVM', 'us', 'L2-norm', 'objective', 'function', 'improvement', 'aspect', 'classification', 'accuracy', 'reduce', 'effect', 'noise', 'outliers.']\n",
      "abstract\\19.txt\n",
      "\n",
      "['This', 'paper', 'investigates', 'improve', 'fuzzy', 'multicategory', 'support', 'vector', 'machine', 'classifier', '(IFMSVM).', 'It', 'us', 'knowledge', 'ambiguity', 'associate', 'membership', 'data', 'sample', 'give', 'class', 'relative', 'location', 'origin,', 'improve', 'classification', 'performance', 'high', 'generalization', 'capability.', 'In', 'aspects,', 'classify', 'accuracy', 'new', 'algorithm', 'well', 'classical', 'support', 'vector', 'classification', 'algorithms.', 'Numerical', 'simulation', 'show', 'feasibility', 'effectiveness', 'algorithm']\n",
      "abstract\\2.txt\n",
      "\n",
      "['This', 'paper', 'firstly', 'analysis', 'actual', 'underwriting', 'method', 'Chinese', 'life', 'insurance', 'companies,', 'point', 'merit', 'shortcoming', 'methods.', 'Then', 'incomplete', 'database', 'insurance', 'company', 'mine', 'data', \"mining's\", 'association', 'rule', 'algorithm.', 'Thirdly', 'support', 'vector', 'machine', '(SVM)', 'apply', 'underwriting', 'process', 'classify', 'applicants.', 'Finally', 'direction', 'improve', 'algorithm', 'point', 'out.', 'The', 'algorithm', 'propose', 'paper', 'promising', 'future', 'underwriting', 'process.']\n",
      "abstract\\20.txt\n",
      "\n",
      "['Active', 'learn', 'hot', 'topic', 'machine', 'learn', 'field.', 'The', 'main', 'task', 'active', 'learn', 'automatically', 'select', 'representative', 'instance', 'efficiently', 'reduce', 'sample', 'complexity.', 'This', 'paper', 'present', 'brief', 'survey', 'active', 'learn', 'regard', 'selection', 'methods,', 'query', 'strategies,', 'application', 'related', 'works.']\n",
      "abstract\\21.txt\n",
      "\n",
      "['Analyzed', 'theoretically,', '/spl', 'nu/-SVM', 'found', 'over-dependent', 'training', 'sample,', 'even', 'sample', 'value.', 'This', 'dependence', 'would', 'result', 'time', 'training,', 'support', 'vector', 'decision', 'time.', 'In', 'order', 'overcome', 'problem,', 'propose', 'new', '/spl', 'nu/-SVM.', 'This', 'new', '/spl', 'nu/-SVM', 'multiplies', 'slack', 'variable', 'objective', 'function', 'weight', 'factor,', 'automatically', 'computes', 'weight', 'factor', 'number', 'correspond', 'sample', 'value', 'training.', 'Theoretical', 'analysis', 'result', 'experiment', 'show', 'new', '/spl', 'nu/-SVM', 'classification', 'precision', 'rate', 'standard', '/spl', 'nu/-SVM', 'new', '/spl', 'nu/-SVM', 'faster', '/spl', 'nu/-SVM', 'training', 'decision', 'training', 'set', 'value', 'samples.']\n",
      "abstract\\22.txt\n",
      "\n",
      "['In', 'paper,', 'use', 'deep', 'learn', 'method,', 'restrict', 'Boltzmann', 'machine,', 'nonlinear', 'system', 'identification.', 'The', 'neural', 'model', 'deep', 'architecture', 'generate', 'random', 'search', 'method.', 'The', 'initial', 'weight', 'deep', 'neural', 'model', 'obtain', 'restrict', 'Boltzmann', 'machines.', 'To', 'identify', 'nonlinear', 'systems,', 'propose', 'special', 'unsupervised', 'learn', 'method', 'input', 'data.', 'The', 'normal', 'supervise', 'learn', 'use', 'train', 'weight', 'output', 'data.', 'The', 'modify', 'algorithm', 'validate', 'model', 'two', 'benchmark', 'systems.']\n",
      "abstract\\23.txt\n",
      "\n",
      "['In', 'order', 'accurately', 'build', \"learner's\", 'learn', 'style', 'E-Learning,', 'accord', 'need', 'preference', 'provide', 'personalize', 'learn', 'material', 'harmonious', 'human-computer', 'interaction', 'environment.', 'This', 'paper', 'combine', 'Felder-Silverman', 'learn', 'style', 'support', 'vector', 'machine', 'technology,', 'use', 'machine', 'learn', 'technology', 'learner', 'build', 'dynamic', 'learn', 'style.', 'Through', 'analysis', 'Emotion', 'recognition', 'interaction', 'personalize', 'E-Learning', 'base', 'statistical', 'learn', 'theory', 'support', 'vector', 'machine', 'technology,', 'demonstrates', 'correctness', 'feasibility', 'use', 'support', 'vector', 'machine', 'build', 'learn', 'styles.', 'The', 'combination', 'support', 'vector', 'machine,', 'emotion', 'recognition', 'interaction', 'personalize', 'E-Learning', 'make', 'great', 'contribution', 'build', 'human-computer', 'interaction', 'environment.']\n",
      "abstract\\24.txt\n",
      "\n",
      "['Summary', 'form', 'given.', 'Learning', 'become', 'central', 'problem', 'try', 'understand', 'intelligence', 'try', 'develop', 'intelligent', 'machines.', 'The', 'paper', 'outline', 'previous', 'effort', 'develop', 'machine', 'learn.', 'It', 'sketch', \"authors's\", 'work', 'statistical', 'learn', 'theory', 'theoretical', 'result', 'problem', 'classification', 'function', 'approximation', 'connect', 'regularization', 'theory', 'support', 'vector', 'machines.', 'The', 'main', 'application', 'focus', 'classification', '(and', 'regression)', 'various', 'domains-such', 'sound,', 'text,', 'video', 'bioinformatics.', 'In', 'particular,', 'paper', 'describe', 'evolution', 'trainable', 'object', 'detection', 'system', 'classify', 'objects-such', 'face', 'people', 'cars-in', 'complex', 'clutter', 'images.', 'Finally,', 'speculates', 'implication', 'research', 'brain', 'work', 'review', 'data', 'provide', 'glimpse', '3D', 'object', 'represent', 'visual', 'cortex.']\n",
      "abstract\\25.txt\n",
      "\n",
      "['Due', 'complexity', 'flexibility', 'natural', 'language,', 'automatic', 'linguistic', 'knowledge', 'acquisition', 'application', 'research', 'becomes', 'difficult.', 'In', 'paper,', 'present', 'machine', 'learn', 'method', 'automatically', 'acquire', 'Chinese', 'linguistic', 'ontology', 'knowledge', 'typical', 'corpus.', 'This', 'study,', 'first,', 'define', 'description', 'frame', 'Chinese', 'linguistic', 'ontology', 'knowledge,', 'then,', 'automatically', 'acquire', 'usage', 'Chinese', 'word', 'co-occurrence', 'context', 'use', 'semantic,', 'pragmatics,', 'syntactic,', 'etc', 'corpus,', 'final,', 'information', 'representation', 'act', 'Chinese', 'linguistic', 'ontology', 'knowledge', 'bank.', 'We', 'complete', 'two', 'group', 'experiments,', 'i.e.', 'document', 'similarity', 'computing,', 'text', 'reorder', 'information', 'retrieval.', 'Compared', 'previous', 'works,', 'propose', 'method', 'solves', 'inferior', 'precision', 'nature', 'language', 'processing.']\n",
      "abstract\\26.txt\n",
      "\n",
      "['The', 'recent', 'success', 'commercial', 'cognitive', 'AI', 'application', 'cast', 'spotlight', 'knowledge', 'graph', 'benefit', 'consume', 'structure', 'semantic', 'data.', 'Today,', 'knowledge', 'graph', 'ubiquitous', 'extent', 'organization', 'often', 'view', '“single', 'source', 'truth”', 'data', 'digital', 'artifacts.', 'In', 'organizations,', 'however,', 'Big', 'Data', 'come', 'many', 'different', 'form', 'include', 'time', 'series,', 'images,', 'unstructured', 'text,', 'often', 'suitable', 'efficient', 'storage', 'within', 'knowledge', 'graph.', 'This', 'paper', 'present', 'Semantics', 'Toolkit', '(SemTK),', 'framework', 'enables', 'access', 'polyglot-persistent', 'Big', 'Data', 'store', 'give', 'appearance', 'data', 'fully', 'capture', 'within', 'knowledge', 'graph.', 'SemTK', 'allows', 'data', 'store', 'across', 'multiple', 'storage', 'platform', '(e.g.,', 'Big', 'Data', 'store', 'Hadoop,', 'graph', 'databases,', 'semantic', 'triple', 'stores)', 'best-suited', 'platform', 'adopt', 'data', 'type', 'maintain', 'single', 'logical', 'interface', 'point', 'access,', 'thereby', 'give', 'user', 'knowledge-driven', 'veneer', 'across', 'data.', 'We', 'describe', 'ease', 'use', 'benefit', 'construct', 'query', 'polystore', 'knowledge', 'graph', 'SemTK', 'via', 'four', 'industrial', 'use', 'case', 'GE.']\n",
      "abstract\\27.txt\n",
      "\n",
      "['As', 'data', 'increase', 'explosively', 'due', 'development', 'social', 'network', 'cloud', 'computing,', 'new', 'challenge', 'storing,', 'processing,', 'analyze', 'large', 'volume', 'data.', 'The', 'traditional', 'technology', 'become', 'proper', 'solution', 'process', 'big', 'data', 'big', 'data', 'platform', 'begin', 'emerge.', 'It', 'certain', 'big', 'data', 'platform', 'help', 'user', 'develop', 'analysis', 'service', 'effectively.', 'However,', 'still', 'take', 'long', 'time', 'collect', 'data,', 'develop', 'algorithm', 'analytics', 'services.', 'We', 'present', 'collaborative', 'big', 'data', 'analytics', 'platform', 'big', 'data', 'service.', 'Developers', 'collaborate', 'platform', 'share', 'data,', 'algorithms,', 'services.', 'Therefore,', 'paper', 'describes', 'big', 'data', 'analytics', 'platform', 'effectively', 'support', 'manage', 'big', 'data', 'develop', 'analytics', 'algorithm', 'services,', 'collaborate', 'data', 'owners,', 'data', 'scientists,', 'service', 'developer', 'Web.', 'Finally,', 'introduce', 'CCTV', 'metadata', 'analytics', 'service', 'developed', 'platform.']\n",
      "abstract\\28.txt\n",
      "\n",
      "['The', 'rapid', 'converge', 'big', 'data', 'IoT', '(Internet', 'Things)', 'technology', 'provide', 'opportunity', 'area', 'road', 'traffic', 'applications.', 'In', 'paper,', 'discus', 'timeline', 'visualization', 'tool', 'enables', 'u', 'well', 'understand', 'traffic', 'behavior', 'road', 'traffic', 'big', 'data.']\n",
      "abstract\\29.txt\n",
      "\n",
      "['In', 'paper,', 'describe', 'ongoing', 'research', 'aim', 'define', 'Requirements', 'Engineering', 'Artefact', 'Model', '(REAM)', 'context', 'Big', 'Data', 'software', 'applications.', 'This', 'model', 'aim', 'provide', '“big', 'picture”', 'Requirements', 'Engineering', 'work', 'product', 'create', 'use', 'Big', 'Data', 'software', 'development', 'projects.', 'REAM', 'important', 'tool', 'use', 'reference', 'definition', 'domain-specific', 'RE', 'models,', 'system', 'life-cycle', 'process', 'artefact-centered', 'processes,', 'currently', 'bereft', 'Big', 'Data', 'Software', 'Engineering', 'research.']\n",
      "abstract\\3.txt\n",
      "\n",
      "['Decision', 'tree', 'induction', 'one', 'useful', 'approach', 'extract', 'classification', 'knowledge', 'set', 'feature-based', 'instances.', 'The', 'popular', 'heuristic', 'information', 'use', 'decision', 'tree', 'generation', 'minimum', 'entropy.', 'This', 'heuristic', 'information', 'serious', 'disadvantage-the', 'poor', 'generalization', 'capability', '[3].', 'Support', 'vector', 'machine', '(SVM)', 'classification', 'technique', 'machine', 'learn', 'base', 'statistical', 'learn', 'theory.', 'It', 'good', 'generalization.', 'Considering', 'relationship', 'classification', 'margin', 'support', 'vector', 'machine(SVM)', 'generalization', 'capability,', 'large', 'margin', 'SVM', 'use', 'heuristic', 'information', 'decision', 'tree,', 'order', 'improve', 'generalization', 'capability.', 'This', 'paper', 'proposes', 'decision', 'tree', 'induction', 'algorithm', 'base', 'large', 'margin', 'heuristic.', 'Comparing', 'binary', 'decision', 'tree', 'use', 'minimum', 'entropy', 'heuristic', 'information,', 'experiment', 'show', 'generalization', 'capability', 'improve', 'use', 'new', 'heuristic.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\30.txt\n",
      "\n",
      "['The', 'Federal', 'Big', 'Data', 'Working', 'Group', 'support', 'Federal', 'Big', 'Data', 'Initiative', 'endorse', 'Federal', 'Government', 'agencies.', 'This', 'work', 'group', 'us', 'meetups', 'onsite', 'virtual', 'participation', 'share', 'best', 'practice', 'implementation', 'Big', 'Data', 'application', 'government', 'science', 'communities.', 'Decision-makers', 'scientific', 'community', 'interact', 'data', 'science', 'order', 'take', 'advantage', 'Big', 'Data', 'transformation', 'information', 'use', 'science,', 'decision', 'support,', 'data', 'discovery', 'data', 'publishing.', 'The', 'work', 'group', 'federates', 'use', 'cases,', 'data', 'publications,', 'solution', 'technologies.', 'The', 'range', 'topic', 'illustrate', 'keynote', 'panel', 'discussion', 'recent', 'Big', 'Data', 'conference', 'summary', 'recent', 'work', 'group', 'meetups.']\n",
      "abstract\\31.txt\n",
      "\n",
      "['This', 'paper', 'outline', 'big', 'data', 'infrastructure', 'processing', 'data', 'streams.', 'Our', 'project', 'distribute', 'stream', 'compute', 'platform', 'provide', 'cost-effective', 'large-scale', 'big', 'data', 'service', 'develop', 'data', 'stream', 'management', 'system.', 'This', 'research', 'contributes', 'advance', 'feasibility', 'big', 'data', 'processing', 'distributed,', 'real-time', 'computation', 'even', 'overloaded.']\n",
      "abstract\\32.txt\n",
      "\n",
      "['With', 'continuous', 'increase', 'heterogeneous', 'multimedia', 'data,', 'question', 'access', 'big', 'multimedia', 'data', 'efficiently', 'become', 'crucial', 'importance.', 'In', 'order', 'provide', 'fast', 'access', 'complex', 'multimedia', 'data,', 'propose', 'approximate', 'content-based', 'feature', 'multimedia', 'object', 'mean', 'generative', 'models.', 'The', 'propose', 'gradient-based', 'signature', 'epitomize', 'high', 'quality', 'content-based', 'approximation', 'multimedia', 'object', 'facilitate', 'efficient', 'index', 'query', 'processing', 'large', 'scale.']\n",
      "abstract\\33.txt\n",
      "\n",
      "['In', 'paper,', 'address', 'problem', 'data', 'confidentiality', 'big', 'data', 'analytics.', 'In', 'many', 'fields,', 'much', 'useful', 'pattern', 'extract', 'apply', 'machine', 'learn', 'technique', 'big', 'data.', 'However,', 'data', 'confidentiality', 'must', 'protected.', 'In', 'many', 'scenarios,', 'data', 'confidentiality', 'could', 'well', 'prerequisite', 'data', 'shared.', 'We', 'present', 'scheme', 'provide', 'provable', 'secure', 'data', 'confidentiality', 'discus', 'various', 'technique', 'optimize', 'performance', 'system.']\n",
      "abstract\\34.txt\n",
      "\n",
      "['This', 'paper', 'analyze', 'challenge', 'data', 'management', 'army', 'data', 'engineering,', 'big', 'data', 'volume,', 'data', 'heterogeneous,', 'high', 'rate', 'data', 'generation', 'update,', 'high', 'time', 'requirement', 'data', 'processing,', 'widely', 'separate', 'data', 'sources.', 'We', 'discuss', 'disadvantage', 'traditional', 'data', 'management', 'technology', 'deal', 'problems.', 'We', 'also', 'highlight', 'key', 'problem', 'data', 'management', 'army', 'data', 'engineering', 'include', 'data', 'integration,', 'data', 'analysis,', 'representation', 'data', 'analysis', 'results,', 'evaluation', 'data', 'quality.']\n",
      "abstract\\35.txt\n",
      "\n",
      "['Data', 'everywhere,', 'non-expert', 'user', 'must', 'able', 'exploit', 'order', 'extract', 'knowledge,', 'get', 'insight', 'make', 'well-informed', 'decisions.', 'The', 'value', 'discover', 'knowledge', 'big', 'data', 'could', 'great', 'value', 'available', 'later', 'consumption', 'reusing.', 'In', 'paper,', 'present', 'infrastructure', 'allows', 'non-expert', 'user', '(i)', 'apply', 'user-friendly', 'data', 'mining', 'technique', 'big', 'data', 'sources,', '(ii)', 'share', 'result', 'Linked', 'Open', 'Data', '(LOD).', 'The', 'main', 'contribution', 'paper', 'approach', 'democratize', 'big', 'data', 'reuse', 'knowledge', 'gain', 'data', 'mining', 'process', 'semantically', 'annotate', 'LOD,', 'obtain', 'Linked', 'Open', 'Knowledge.', 'Our', 'work', 'base', 'model-driven', 'viewpoint', 'order', 'easily', 'deal', 'wide', 'diversity', 'open', 'data', 'formats.']\n",
      "abstract\\36.txt\n",
      "\n",
      "['This', 'paper', 'introduces', 'general', 'framework', 'support', 'data-driven', 'privacy-preserving', 'big', 'data', 'management', 'distribute', 'environments,', 'emerge', 'Cloud', 'settings.', 'The', 'propose', 'framework', 'view', 'alternative', 'classical', 'approach', 'privacy', 'big', 'data', 'ensure', 'via', 'security-inspired', 'protocol', 'check', 'several', '(protocol)', 'layer', 'order', 'achieve', 'desire', 'privacy.', 'Unfortunately,', 'injects', 'considerable', 'computational', 'overhead', 'overall', 'process,', 'thus', 'introduce', 'relevant', 'challenge', 'considered.', 'Our', 'approach', 'instead', 'try', 'recognize', '\"pedigree\"', 'suitable', 'summary', 'data', 'representative', 'compute', 'top', 'target', 'big', 'data', 'repositories,', 'hence', 'avoid', 'computational', 'overhead', 'due', 'protocol', 'checking.', 'We', 'also', 'provide', 'relevant', 'realization', 'framework', 'above,', 'so-called', 'Data-dRIven', 'aggregate-PROvenance', 'privacypreserving', 'big', 'Multidimensional', 'data', '(DRIPROM)', 'framework,', 'specifically', 'considers', 'multidimensional', 'data', 'case', 'interest.']\n",
      "abstract\\37.txt\n",
      "\n",
      "['Big', 'data', 'tsunami', 'hit', 'Malaysia', 'recently', 'awaken', 'industry', 'academy', 'community', 'aggressively', 'address', 'insight,', 'hindsight', 'foresight', 'challenge', 'ensure', 'Malaysia', 'among', 'top', 'world', 'player', 'big', 'data', 'information', 'economy', 'next', 'decade.', 'Rapid', 'development', 'Information', 'Communication', 'Technology', '(ICT)', 'era', 'significant', 'due', 'increase', 'number', 'user', 'access', 'data', 'keep', 'grow', 'time.', 'This', 'phenomenon', 'coin', 'big', 'data.', 'What', 'Big', 'data???', 'We', 'address', 'big', 'data', 'asset', 'need', 'unique', 'platform', 'deal', 'bizarre', 'behavior', 'datasets', 'whose', 'size', 'beyond', 'ability', 'typical', 'data', 'storage', 'manage,', 'mine', 'analyze', 'accordingly.', 'This', 'bizarre', 'behavior', 'require', 'three', 'main', 'personalities:', 'volume,', 'velocity,', 'variety', 'basically', 'need', 'new', 'architecture,', 'techniques,', 'algorithms,', 'analytics', 'uncover', 'golden', 'hidden', 'knowledge', 'information', 'obesity.', 'From', 'perspectives,', 'demonstrate', 'experience', 'set', 'Data', 'Science/Big', 'Data', 'platform,', 'algorithm', 'tool', 'align', 'big', 'data', 'plug', 'play', 'within', 'academic', 'environment', 'well', 'service', 'community', 'industries.']\n",
      "abstract\\38.txt\n",
      "\n",
      "['In', 'Big', 'Data', 'Era,', 'data', 'core', 'governmental,', 'institutional,', 'private', 'organization.', 'Efforts', 'gear', 'towards', 'extract', 'highly', 'valuable', 'insight', 'cannot', 'happen', 'data', 'poor', 'quality.', 'Therefore,', 'data', 'quality', '(DQ)', 'consider', 'key', 'element', 'Big', 'data', 'processing', 'phase.', 'In', 'stage,', 'low', 'quality', 'data', 'penetrate', 'Big', 'Data', 'value', 'chain.', 'This', 'paper,', 'address', 'data', 'quality', 'rule', 'discovery', '(DQR)', 'evaluation', 'quality', 'prior', 'Big', 'Data', 'pre-processing.', 'We', 'propose', 'DQR', 'discovery', 'model', 'enhance', 'accurately', 'target', 'pre-processing', 'activity', 'base', 'quality', 'requirements.', 'We', 'defined,', 'set', 'pre-processing', 'activity', 'associate', 'data', 'quality', 'dimension', \"(DQD's)\", 'automatize', 'DQR', 'generation', 'process.', 'Rules', 'optimization', 'apply', 'validate', 'rule', 'avoid', 'multi-passes', 'pre-processing', 'activity', 'eliminates', 'duplicate', 'rules.', 'Conducted', 'experiment', 'show', 'increase', 'quality', 'score', 'apply', 'discover', 'optimize', \"DQR's\", 'data.']\n",
      "abstract\\39.txt\n",
      "\n",
      "['Centers', 'Medicare', 'Medicaid', 'Services', '(CMS)', 'publishes', 'Medicare', 'Part', 'C', 'Star', 'Ratings', 'year', 'measure', 'quality', 'care', 'Medicare', 'Advantage', '(MA)', 'contracts.', 'One', 'key', 'measure', 'Complaints', 'Health', 'Plan,', 'capture', 'Complaints', 'Tracking', 'Module', '(CTM).', 'Complaints', 'result', 'CTM', 'rare', 'events:', 'MA', 'contract', '2-5', 'star', 'ratings,', 'number', 'complaint', 'every', '1,000', 'member', 'range', '.10', '1.84', 'last', '5', 'years.', 'Reducing', 'number', 'complaint', 'extremely', 'important', 'MA', 'plan', 'impact', 'CMS', 'reimbursement', 'MA', 'plans.', 'Forecasting', 'reduce', 'complaint', 'extremely', 'technically', 'challenge', 'task,', 'involves', 'ethic', 'consideration', \"patients'\", 'right', 'privacy.', 'In', 'research,', 'construct', 'big', 'data', 'analytics', 'framework', 'forecasting', 'rare', 'customer', 'complaints.', 'First,', 'built', 'big', 'data', 'ingestion', 'pipeline', 'Hadoop', 'platform:', 'a)', 'Ingest', 'MA', \"plan's\", 'customer', 'complaint', 'data', 'CTM', 'past', '3', 'years.', 'b)', 'Ingest', 'health', \"plan's\", 'call', 'center', 'data', 'MA', 'member', 'past', '3', 'years,', 'include', 'structure', 'data', 'unstructured', 'text', 'script', 'calls.', 'c)', 'Ingest', 'MA', \"members'\", 'medical', 'claims,', 'include', \"members'\", 'demographic', 'enrollment', 'history.', 'd)', 'Ingest', 'MA', \"members'\", 'pharmacy', 'claims.', 'e)', 'Integrate', 'unified', 'data', 'sources,', 'enrich', 'data', 'additional', 'engineer', 'feature', 'big', 'wide', 'table,', 'one', 'row', 'per', 'member', 'analysis', 'modeling.', 'Second,', 'design', 'unique', 'decision', 'tree', 'base', 'Large', 'Ensemble', 'Over-Sampling', '(LEOS)', 'algorithm,', 'mimic', 'random', 'forest', 'extreme', 'oversampling', 'target', 'class', 'increase', 'bias,', 'leverage', 'parallel', 'compute', 'Hadoop', 'cluster', 'generate', 'thousand', 'fix', 'size', 'training', 'data', 'sets,', 'dataset', 'training', 'decision', 'tree', 'similar', 'fix', 'tree', 'structure,', 'ensemble', 'them.', 'Third,', 'validate', 'framework', 'LEOS', 'learn', 'algorithm', 'real', 'data,', 'also', 'discuss', 'ethic', 'issue', 'encounter', 'handle', 'data', 'apply', 'finding', 'research.']\n",
      "abstract\\4.txt\n",
      "\n",
      "['Determination', 'model', 'complexity', 'challenge', 'issue', 'solve', 'computer', 'vision', 'problem', 'use', 'restrict', 'boltzmann', 'machine', '(RBMs).', 'Many', 'algorithm', 'feature', 'learn', 'depend', 'cross-validation', 'empirical', 'method', 'optimize', 'number', 'features.', 'In', 'work,', 'propose', 'learn', 'algorithm', 'find', 'optimal', 'model', 'complexity', 'RBMs', 'incrementing', 'hidden', 'layer.', 'The', 'propose', 'algorithm', 'compose', 'two', 'processes:', '1)', 'determine', 'incrementation', 'necessity', 'neuron', '2)', 'compute', 'number', 'additional', 'feature', 'increment.', 'Specifically,', 'propose', 'algorithm', 'us', 'normalize', 'reconstruction', 'error', 'order', 'determine', 'incrementation', 'necessity', 'prevent', 'unnecessary', 'increment', 'number', 'feature', 'training.', 'Our', 'experimental', 'result', 'demonstrate', 'propose', 'algorithm', 'converges', 'optimal', 'number', 'feature', 'single', 'layer', 'RBMs.', 'In', 'classification', 'results,', 'model', 'could', 'outperform', 'non-incremental', 'RBM.']\n",
      "abstract\\40.txt\n",
      "\n",
      "['Big', 'data', 'gathering', 'mining', 'pipeline', 'CRM', 'use', 'open-source']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\40.txt\n",
      "\n",
      "['Customer', 'Relationship', 'Management', '(CRM)', 'currently', 'fast', 'grow', 'sector', 'enterprise', 'software,', 'estimate', 'increase', 'worldwide', '2017.', 'CRM', 'technology', 'increasingly', 'use', 'data', 'mining', 'primitive', 'across', 'multiple', 'applications.', 'At', 'time,', 'growth', 'big', 'data', 'lead', 'evolution', 'open', 'source', 'big', 'data', 'software', 'stack', '(primarily', 'power', 'Apache', 'software)', 'rival', 'traditional', 'enterprise', 'database', '(RDBMS)', 'stacks.', 'New', 'technology', 'Kafka,', 'Storm,', 'HBase', 'significantly', 'enrich', 'open', 'source', 'stack,', 'alongside', 'establish', 'technology', 'Hadoop', 'MapReduce', 'Mahout.', 'Today,', 'enterprise', 'choice', 'make', 'regard', 'stack', 'choose', 'power', 'big', 'data', 'applications.', 'However,', 'publish', 'study', 'literature', 'enterprise', 'big', 'data', 'pipeline', 'built', 'use', 'open', 'source', 'component', 'support', 'CRM.', 'Specific', 'question', 'enterprise', 'include:', 'data', 'process', 'analyze', 'pipelines?', 'What', 'building', 'block', 'pipelines?', 'How', 'long', 'step', 'processing', 'take?', 'In', 'work,', 'answer', 'question', 'large', 'scale', '(serving', '100M', 'customers)', 'industrial', 'CRM', 'pipeline', 'incorporates', 'data', 'mining,', 'serf', 'several', 'applications.', 'Our', 'pipeline', 'has,', 'broadly,', 'two', 'parts.', 'The', 'first', 'data', 'gathering', 'part', 'us', 'Kafka,', 'Storm,', 'HBase.', 'The', 'second', 'data', 'mining', 'part', 'us', 'Mahout', 'Hadoop', 'MapReduce.', 'We', 'also', 'provide', 'timing', 'common', 'task', 'second', 'part', 'data', 'preprocessing', 'machine', 'learning,', 'clustering,', 'reservoir', 'sampling,', 'frequent', 'itemset', 'extraction.']\n",
      "abstract\\41.txt\n",
      "\n",
      "['Big', 'data', 'penetrate', 'various', 'industry', 'business', 'functions,', 'become', 'important', 'factor', 'production', 'global', 'economy.', 'In', 'big', 'data', 'technology', 'system,', 'big', 'data', 'collection', 'basis.', 'The', 'storage,', 'analysis,', 'integration', 'visualization', 'unstructured', 'data', 'semi-structured', 'data', 'become', 'important', 'focus', 'big', 'data', 'innovation.', 'Traditional', 'structure', 'data', 'longer', 'core', 'big', 'data.', 'Based', 'life', 'cycle', 'theory,', 'use', 'new', 'digital', 'technology,', 'acquisition,', 'processing,', 'storage,', 'organization', 'copyright', 'protection,', 'cluster', 'high', 'concurrency', 'retrieval', 'dynamic', 'scheduling,', 'intelligent', 'digital', 'display,', 'coal', 'mine', 'industry', 'information', 'data', 'collect', 'integrated,', 'realize', 'centralize', 'management,', 'unified', 'retrieval', 'joint', 'exhibition', 'information', 'resources,', 'provide', 'technical', 'mean', 'reference', 'digital', 'construction', 'heterogeneous', 'coal', 'mine', 'information', 'data', 'mean', 'big', 'data', 'thinking.']\n",
      "abstract\\42.txt\n",
      "\n",
      "['Herein', 'present', 'novel', 'big-data', 'framework', 'healthcare', 'applications.', 'Healthcare', 'data', 'well', 'suit', 'bigdata', 'processing', 'analytics', 'variety,', 'veracity', 'volume', 'type', 'data.', 'In', 'recent', 'times,', 'many', 'area', 'within', 'healthcare', 'identify', 'directly', 'benefit', 'treatment.', 'However,', 'set', 'type', 'architecture', 'trivial.', 'We', 'present', 'novel', 'approach', 'building', 'big-data', 'framework', 'adapt', 'various', 'healthcare', 'application', 'relative', 'use,', 'make', 'one-stop', '“Big-Data-Healthcare-in-a-Box”.']\n",
      "abstract\\43.txt\n",
      "\n",
      "['Currently,', 'on-line', 'monitoring', 'measure', 'system', 'power', 'quality', 'accumulate', 'huge', 'amount', 'data.', 'In', 'age', 'big', 'data,', 'data', 'integrate', 'various', 'system', 'face', 'big', 'data', 'application', 'problems.', 'This', 'paper', 'proposes', 'data', 'quality', 'assessment', 'system', 'method', 'on-line', 'monitoring', 'measure', 'system', 'power', 'quality', 'base', 'big', 'data', 'data', 'provenance', 'ass', 'integrity,', 'redundancy,', 'accuracy,', 'timeliness,', 'intelligence', 'consistency', 'data', 'set', 'single', 'data.', 'Specific', 'assessment', 'rule', 'conforms', 'situation', 'on-line', 'monitoring', 'measure', 'system', 'power', 'quality', 'devise', 'found', 'data', 'quality', 'problems.', 'Thus', 'provide', 'strong', 'data', 'support', 'big', 'data', 'application', 'power', 'quality.']\n",
      "abstract\\44.txt\n",
      "\n",
      "['This', 'paper', 'attempt', 'construct', 'analysis', 'model', 'city', 'price,', 'combine', 'big', 'data', 'system', 'information', 'city', 'price,', 'provide', 'reference', 'government', 'implement', 'policy', 'accurate', 'price', 'control.', 'This', 'paper', 'considers', 'analysis', 'system', 'city', 'price', 'include', 'decision-making', 'layer,', 'support', 'layer', 'show', 'layer', 'conceptual', 'level,', 'transmission', 'path', 'include', 'data', 'collection,', 'data', 'management,', 'data', 'mining,', 'decision', 'make', 'safety', 'protection.', 'come', 'construction', 'subsystem,', 'technological', 'tool', 'data', 'mining,', 'cloud', 'compute', 'visualization', 'used,', 'mainly', 'order', 'build', 'data', 'acquisition', 'subsystem,', 'data', 'management', 'subsystem,', 'data', 'analysis', 'subsystem,', 'data', 'transmission', 'subsystem', 'on,', 'provide', 'graphic', 'description', 'correspond', 'technological', 'path', 'time.']\n",
      "abstract\\45.txt\n",
      "\n",
      "['The', 'conventional', 'method', 'data', 'analytics', 'flight', 'safety', 'monitoring', 'met', 'many', 'bottlenecks.', 'This', 'paper', 'analyzes', 'insufficiency', 'preliminary', 'business', 'process', 'airline.', 'For', 'purpose', 'meeting', 'requirement', 'efficiency', 'accuracy', 'avoid', 'drawback', 'encounter', 'before,', 'architectural', 'framework', 'flight', 'safety', 'monitoring', 'platform', 'utilize', 'big', 'data', 'technology', 'propose', 'demonstrate', 'function', 'module', 'structure', 'logical', 'structure.', 'The', 'platform', 'implement', 'divide', 'system', 'five', 'subsystems,', 'namely', 'data', 'acquisition,', 'data', 'decoding,', 'data', 'storage,', 'data', 'analysis', 'visualization.']\n",
      "abstract\\46.txt\n",
      "\n",
      "['Big', 'Data', 'constitutes', 'opportunity', 'company', 'empower', 'analysis.', 'However,', 'moment', 'standard', 'way', 'approach', 'Big', 'Data', 'projects.', 'This,', 'couple', 'complex', 'nature', 'Big', 'Data,', 'cause', 'many', 'Big', 'Data', 'project', 'fail', 'rarely', 'obtain', 'expect', 'return', 'investment.', 'In', 'paper,', 'present', 'methodology', 'tackle', 'Big', 'Data', 'project', 'systematic', 'way,', 'avoid', 'aforementioned', 'problems.', 'To', 'end,', 'review', 'state', 'art,', 'identify', 'prominent', 'problem', 'surround', 'Big', 'Data', 'projects,', 'best', 'practice', 'methods.', 'Then,', 'define', 'methodology', 'describe', 'step', 'step', 'technique', 'could', 'apply', 'combine', 'order', 'tackle', 'problem', 'identify', 'increase', 'success', 'rate', 'Big', 'Data', 'projects.']\n",
      "abstract\\47.txt\n",
      "\n",
      "['In', 'August', '2015,', 'new', 'seafloor', 'observatory', 'deployed', 'Galway', 'Bay,', 'Ireland.', 'The', 'sensor', 'observatory', 'platform', 'connect', 'fibre-optic', 'cable', 'shore', 'station,', 'broadband', 'connection', 'allows', 'data', 'transfer', 'Marine', \"Institute's\", 'data', 'centre.', 'This', 'setup', 'involve', 'development', 'new', 'data', 'acquisition', 'system', 'take', 'advantage', 'open', 'source', 'stream', 'data', 'solution', 'developed', 'response', 'Big', 'Data', 'paradigm,', 'particular', 'Velocity', 'aspect.', 'This', 'activity', 'merges', 'concept', 'arena', 'Big', 'Data', 'Internet', 'Things', 'data', 'standardisation', 'normally', 'considered.', 'This', 'paper', 'considers', 'architecture', 'implement', 'stream', 'marine', 'data', 'instrument', 'end', 'user', 'offer', 'suggestion', 'standardise', 'data', 'streams.']\n",
      "abstract\\48.txt\n",
      "\n",
      "['We', 'collect', '79,012', 'article', '1916-2016', 'related', 'big', 'data', 'determine', 'topic', 'study', 'much', 'literature', 'focus', 'privacy', 'security-related', 'keywords.', 'The', 'analysis', 'demonstrate', 'big', 'data', 'paradigm', 'commenced', 'late', '2011', 'research', 'production', 'exponentially', 'rise', 'start', '2012,', 'approximate', 'Weibull', 'distribution', 'capture', '82%', 'variance', '(p<;.01).', 'We', 'found', '13', 'dominant', 'topic', 'capture', '49%', 'big', 'data', 'production', 'journal', '2011-2016', 'privacy', 'security', 'topic', 'account', '2%', 'trend', 'recently', 'drop', 'less', '1%', 'Thus,', 'argue', 'need', 'stimulate', 'big', 'data', 'privacy-security', 'research.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\49.txt\n",
      "\n",
      "['As', 'large', 'amount', 'data', 'generate', 'healthcare', 'industry,', 'big', 'data', 'technology', 'use', 'process', 'data.', 'Tobacco', 'smoking', 'significant', 'among', 'youth', 'United', 'States.', 'In', 'research,', 'use', 'big', 'data', 'technique', 'R', 'Tableau', 'explore', 'tobacco', 'smoking', 'trend', 'among', 'youth', 'United', 'States.', 'Results', 'indicate', 'number', 'youth', 'male', 'smoker', 'youth', 'female', 'smokers.', 'The', 'result', 'also', 'indicate', '51', 'percent', 'current', 'youth', 'smoker', 'want', 'quit', 'smoking.']\n",
      "abstract\\5.txt\n",
      "\n",
      "['Text', 'categorization', '(TC)', 'important', 'component', 'many', 'information', 'organization', 'information', 'management', 'tasks.', 'Two', 'key', 'issue', 'TC', 'feature', 'cod', 'classifier', 'design.', 'The', 'Euclidean', 'distance', 'usually', 'chosen', 'similarity', 'measure', 'K-nearest', 'neighbor', 'classification', 'algorithm.', 'All', 'feature', 'vector', 'different', 'function', 'describe', 'samples.', 'So', 'decide', 'different', 'function', 'every', 'feature', 'use', 'feature', 'weight', 'learning.', 'In', 'paper', 'text', 'categorization', 'via', 'K-nearest', 'neighbor', 'algorithm', 'base', 'feature', 'weight', 'learn', 'described.', 'The', 'numerical', 'experiment', 'prove', 'validity', 'learn', 'algorithm.']\n",
      "abstract\\50.txt\n",
      "\n",
      "['In', 'last', 'years,', 'grow', 'interest', 'use', 'Big', 'Data', 'model', 'support', 'advanced', 'data', 'analysis', 'functionalities.', 'Many', 'company', 'organization', 'lack', 'IT', 'expertise', 'adequate', 'budget', 'benefit', 'them.', 'In', 'order', 'fill', 'gap,', 'model-based', 'approach', 'Big', 'Data', 'Analytics-as-a-service', '(MBDAaaS)', 'used.', 'The', 'propose', 'model,', 'compose', 'declarative,', 'procedural', 'deployment', '(sub)', 'models,', 'use', 'select', 'deployable', 'set', 'service', 'base', 'set', 'user', 'preference', 'shape', 'Big', 'Data', 'Campaign', '(BDC).', 'The', 'deployment', 'BDC', 'require', 'selection', 'service', 'carry', 'basis', 'coherent', 'non', 'conflictual', 'user', 'preferences.', 'In', 'paper', 'propose', 'OWL', 'ontology', 'order', 'solve', 'issue.']\n",
      "abstract\\6.txt\n",
      "\n",
      "['This', 'work', 'proposes', 'intelligent', 'learn', 'diagnosis', 'system', 'support', 'Web-based', 'thematic', 'learn', 'model,', 'aim', 'cultivate', \"learners'\", 'ability', 'knowledge', 'integration', 'give', 'learner', 'opportunity', 'select', 'learn', 'topic', 'interested,', 'gain', 'knowledge', 'specific', 'topic', 'surf', 'Internet', 'search', 'related', 'learn', 'courseware', 'discuss', 'learn', 'colleagues.', 'Based', 'log', 'file', 'record', \"learners'\", 'past', 'online', 'learn', 'behavior,', 'intelligent', 'diagnosis', 'system', 'use', 'give', 'appropriate', 'learn', 'guidance', 'assist', 'learner', 'improve', 'study', 'behavior', 'grade', 'online', 'class', 'participation', 'instructor.', 'The', 'achievement', \"learners'\", 'final', 'report', 'also', 'predict', 'diagnosis', 'system', 'accurately.', 'Our', 'experimental', 'result', 'reveal', 'propose', 'learn', 'diagnosis', 'system', 'efficiently', 'help', 'learner', 'expand', 'knowledge', 'surf', 'cyberspace', 'Web-based', '\"theme-based', 'learning\"', 'model.']\n",
      "abstract\\7.txt\n",
      "\n",
      "['Semi-supervised', 'support', 'vector', 'machine', 'extension', 'standard', 'support', 'vector', 'machine', 'machine', 'learn', 'problem', 'real', 'life.', 'However,', 'exist', 'semi-supervised', 'support', 'vector', 'machine', 'algorithm', 'drawback', 'slow', 'training', 'speed,', 'low', 'accuracy,', 'etc.', 'This', 'paper', 'present', 'semi-supervised', 'support', 'vector', 'machine', 'learn', 'algorithm', 'base', 'active', 'learning,', 'train', 'early', 'learner', 'spot', 'labeled-data,', 'selects', 'best', 'training', 'sample', 'training', 'learn', 'active', 'learn', 'reduces', 'learn', 'cost', 'delete', 'non-', 'support', 'vector.', 'Simulative', 'experiment', 'show', 'algorithm', 'may', 'get', 'good', 'learn', 'effect', 'less', 'learn', 'cost.']\n",
      "abstract\\8.txt\n",
      "\n",
      "['Transfer', 'learn', 'aim', 'improve', 'target', 'learn', 'task', 'use', 'related', 'auxiliary', 'learn', 'task', 'data.', 'Most', 'current', 'transfer-learning', 'method', 'focus', 'scenario', 'auxiliary', 'target', 'learn', 'task', 'similar:', 'either', '(some', 'of)', 'auxiliary', 'data', 'directly', 'use', 'training', 'example', 'target', 'task', 'auxiliary', 'target', 'data', 'share', 'representation.', 'However,', 'many', 'case', 'connection', 'auxiliary', 'target', 'task', 'remote.', 'Only', 'feature', 'derive', 'auxiliary', 'data', 'may', 'helpful', 'target', 'learning.', 'We', 'call', 'scenario', 'deep', 'transfer-learning', 'scenario', 'introduce', 'novel', 'transfer-learning', 'method', 'deep', 'transfer.', 'Our', 'method', 'us', 'restrict', 'Boltzmann', 'machine', 'discover', 'set', 'hierarchical', 'feature', 'auxiliary', 'data.', 'We', 'select', 'feature', 'subset', 'helpful', 'target', 'learning,', 'use', 'selection', 'criterion', 'base', 'concept', 'kernel-target', 'alignment.', 'Finally,', 'target', 'data', 'augment', 'select', 'feature', 'training.', 'Our', 'experiment', 'result', 'show', 'transfer', 'method', 'effective.', 'It', 'improve', 'classification', 'accuracy', '10%,', 'even', 'connection', 'auxiliary', 'target', 'task', 'apparent.']\n",
      "abstract\\9.txt\n",
      "\n",
      "['Data', 'mining', 'CRM', 'aim', 'learn', 'available', 'knowledge', 'customer', 'relationship', 'machine', 'learn', 'statistical', 'method', 'instruct', 'strategic', 'behavior', 'obtain', 'profit.', 'In', 'recent', 'years,', 'Support', 'vector', 'machine', '(SVMs)', 'propose', 'power', 'tool', 'machine', 'lean', 'data', 'mining.', 'This', 'paper', 'applies', 'SVMs', 'resolve', 'practical', 'CRM', 'problem', 'company.', 'The', 'final', 'result', 'report', 'good', 'general', 'performance', 'SVMs', 'CRM', 'problem.']\n",
      "abstract\\a1.txt\n",
      "\n",
      "['In', 'paper', 'discus', 'various', 'machine', 'learn', 'approach', 'use', 'mining', 'data.', 'Further', 'distinguish', 'symbolic', 'sub-symbolic', 'data', 'mining', 'methods.', 'We', 'also', 'attempt', 'propose', 'hybrid', 'method', 'combination', 'Artificial', 'Neural', 'Network', '(ANN)', 'Cased', 'Based', 'Reasoning', '(CBR)', 'mining', 'data.']\n",
      "abstract\\a10.txt\n",
      "\n",
      "['In', 'paper,', 'present', 'framework', 'enables', 'medical', 'decision', 'make', 'presence', 'partial', 'information.', 'At', 'core', 'ontology-based', 'automate', 'reasoning,', 'machine', 'learn', 'technique', 'integrate', 'enhance', 'exist', 'patient', 'datasets', 'order', 'address', 'issue', 'miss', 'data.', 'Our', 'approach', 'support', 'interoperability', 'different', 'health', 'information', 'systems.', 'This', 'clarify', 'sample', 'implementation', 'combine', 'three', 'separate', 'datasets', '(patient', 'data,', 'drug-drug', 'interaction', 'drug', 'prescription', 'rules)', 'demonstrate', 'effectiveness', 'algorithm', 'produce', 'effective', 'medical', 'decisions.', 'In', 'short,', 'demonstrate', 'potential', 'machine', 'learn', 'support', 'task', 'critical', 'need', 'medical', 'professional', 'cop', 'miss', 'noisy', 'patient', 'data', 'enable', 'use', 'multiple', 'medical', 'datasets.']\n",
      "abstract\\a11.txt\n",
      "\n",
      "['Support', 'vector', 'machine', '(SVM)', 'become', 'popular', 'tool', 'pattern', 'recognition', 'recent', 'year', 'outstanding', 'learn', 'performance.', 'When', 'deal', 'large-scale', 'learn', 'problems,', 'incremental', 'SVM', 'framework', 'generally', 'use', 'SVM', 'summarize', 'data', 'space', 'concise', 'way.', 'This', 'paper', 'proposes', 'training', 'algorithm', 'incremental', 'SVM', 'recombine', 'method.', 'Considering', 'difference', 'data', 'distribution', 'impact', 'new', 'training', 'data', 'history', 'data,', 'history', 'training', 'dataset', 'new', 'training', 'one', 'divide', 'independent', 'group', 'recombine', 'train', 'classifier.', 'In', 'fact,', 'method', 'implement', 'parallel', 'structure', 'action', 'divide', 'may', 'decrease', 'computation', 'complexity', 'training', 'SVM.', 'Meanwhile,', 'action', 'recombine', 'may', 'weaken', 'potential', 'impact', 'cause', 'difference', 'data', 'distribution.', 'The', 'experiment', 'result', 'text', 'dataset', 'show', 'training', 'algorithm', 'effective', 'classification', 'accuracy', 'propose', 'incremental', 'algorithm', 'superior', 'use', 'batch', 'SVM', 'model.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a12.txt\n",
      "\n",
      "['There', '700,000', 'Rheumatoid', 'Arthritis', '(RA)', 'patient', 'Japan,', 'number', 'patient', 'increase', '30,000', 'annually.', 'The', 'early', 'detection', 'appropriate', 'treatment', 'accord', 'progression', 'RA', 'effective', 'improve', \"patient's\", 'prognosis.', 'The', 'modify', 'Total', 'Sharp', '(mTS)', 'score', 'widely', 'use', 'progression', 'evaluation', 'Rheumatoid', 'Arthritis.', 'The', 'mTS', 'score', 'assessment', 'hand', 'foot', 'X-ray', 'image', 'require', 'several', 'time', 'year,', 'take', 'long', 'time.', 'The', 'automatic', 'mTS', 'score', 'calculation', 'system', 'required.', 'This', 'paper', 'proposes', 'finger', 'joint', 'detection', 'method', 'mTS', 'score', 'estimation', 'method', 'use', 'support', 'vector', 'machine.', 'Experimental', 'result', '45', 'RA', \"patient's\", 'X-ray', 'image', 'show', 'propose', 'method', 'detects', 'finger', 'joint', 'accuracy', '81.4', '%,', 'estimate', 'erosion', 'JSN', 'score', 'accuracy', '50.9,', '64.3', '%,', 'respectively.']\n",
      "abstract\\a13.txt\n",
      "\n",
      "['As', 'increasingly', 'enterprise', 'deploy', 'cloud', 'file-sharing', 'services,', 'add', 'new', 'channel', 'potential', 'insider', 'threat', 'company', 'data', 'IPs.', 'In', 'paper,', 'introduce', 'two-stage', 'machine', 'learn', 'system', 'detect', 'anomalies.', 'In', 'first', 'stage,', 'project', 'access', 'log', 'cloud', 'file-sharing', 'service', 'onto', 'relationship', 'graph', 'use', 'three', 'complementary', 'graph-based', 'unsupervised', 'learn', 'methods:', 'OddBall,', 'PageRank', 'Local', 'Outlier', 'Factor', '(LOF)', 'generate', 'outlier', 'indicators.', 'In', 'second', 'stage,', 'ensemble', 'outlier', 'indicator', 'introduce', 'discrete', 'wavelet', 'transform', '(DWT)', 'method,', 'propose', 'procedure', 'use', 'wavelet', 'coefficient', 'Haar', 'wavelet', 'function', 'identify', 'outlier', 'insider', 'threat.', 'The', 'propose', 'system', 'deployed', 'real', 'business', 'environment,', 'demonstrate', 'effectiveness', 'select', 'case', 'studies.']\n",
      "abstract\\a14.txt\n",
      "\n",
      "['This', 'paper', 'address', 'recent', 'trend', 'machine', 'learn', 'method', 'automatic', 'classification', 'remote', 'sense', '(RS)', 'images.', 'In', 'particular,', 'focus', 'two', 'new', 'paradigms:', 'semisupervised', 'active', 'learning.', 'These', 'two', 'paradigm', 'allow', 'one', 'address', 'classification', 'problem', 'critical', 'condition', 'available', 'label', 'training', 'sample', 'limited.', 'These', 'operational', 'condition', 'usual', 'RS', 'problems,', 'due', 'high', 'cost', 'time', 'associate', 'collection', 'label', 'samples.', 'Semisupervised', 'active', 'learn', 'technique', 'allow', 'one', 'enrich', 'initial', 'training', 'set', 'information', 'improve', 'classification', 'accuracy', 'exploit', 'unlabeled', 'sample', 'require', 'additional', 'label', 'phase', 'user,', 'respectively.', 'The', 'two', 'aforementioned', 'strategy', 'theoretically', 'experimentally', 'analyze', 'consider', 'SVM-based', 'technique', 'order', 'highlight', 'advantage', 'disadvantage', 'strategies.']\n",
      "abstract\\a15.txt\n",
      "\n",
      "['Web', 'filter', 'base', \"user's\", 'demand', 'witness', 'boom', 'interest', 'due', 'development', 'Internet', 'In', 'research', 'community', 'dominant', 'approach', 'problem', 'base', 'machine', 'learn', 'algorithms.', 'Web', 'filter', 'inductive', 'process', 'automatically', 'build', 'filter', 'learn', 'set', 'pre-assigned', 'document', 'description', \"user's\", 'interest,', 'us', 'assign', 'unfiltered', 'Web', 'pages.', 'This', 'survey', 'compare', 'four', 'main', 'machine', 'learn', 'algorithm', '(decision', 'tree,', 'rule', 'induction,', 'Bayesian', 'algorithm', 'support', 'vector', 'machines)', 'Chinese', 'web', 'page', 'set', 'filter', 'effectiveness', 'computer', 'resource', 'consumed,', 'focus', 'influence', 'feature', 'set', 'size', 'training', 'set', 'size.', 'It', 'induces', 'support', 'vector', 'machine', 'earn', 'high', 'score', 'Chinese', 'Web', 'filter', 'applications.']\n",
      "abstract\\a16.txt\n",
      "\n",
      "['Imbalanced', 'distribution', 'mis-classified', 'cost', 'two', 'class', 'make', 'conventional', 'classification', 'method', 'suffered.', 'This', 'paper', 'propose', 'new', 'fast', 'parallel', 'classification', 'method', 'imbalanced', 'classes.', 'Considering', 'imbalanced', 'distributions,', 'approach', 'adopt', 'fast', 'simple', 'classifier', 'less', 'feature', 'input', 'work', 'parallel', 'complicate', 'one.', 'Most', 'sample', 'would', 'correctly', 'recognize', 'first', 'classifier,', 'second', 'relatively', 'slow', 'classifier', 'could', 'ended.', 'The', 'second', 'one', 'train', 'work', 'less', 'difficult', 'samples.', 'Experimental', 'result', 'machine', 'vision', 'quality', 'inspection', 'show', 'approach', 'could', 'effectively', 'improve', 'classification', 'speed', 'decrease', 'total', 'risk', 'imbalanced', 'classespsila', 'classification.']\n",
      "abstract\\a17.txt\n",
      "\n",
      "['Chinese', 'new', 'word', 'extraction', 'important', 'problem', 'Chinese', 'information', 'processing.', 'In', 'paper', 'new', 'word', 'extraction', 'method', 'base', 'machine', 'learn', 'proposed,', 'context', 'information,', 'word', 'construction', 'rule', 'statistic', 'information', 'combine', 'extract', 'new', 'words.', 'An', 'experiment,', 'base', 'two-character-nouns,', 'show', 'method', 'well', 'improve', 'efficiency', 'accuracy', 'extract', 'new', 'word']\n",
      "abstract\\a18.txt\n",
      "\n",
      "['Neural', 'network', 'hardware', 'implementation', 'reconcile', 'simple', 'hardware', 'topology', 'often', 'complex', 'neural', 'architectures.', 'Field', 'programmable', 'neural', 'array', '(FPNA)', 'define', 'that.', 'Their', 'computation', 'scheme', 'creates', 'numerous', 'virtual', 'neural', 'link', 'mean', 'limited', 'set', 'communication', 'links,', 'whatever', 'device,', 'arithmetic,', 'neural', 'structure.', 'Their', 'concrete', 'use', 'prove', 'allow', 'computation', 'power', 'standard', 'neural', 'model', 'reduce', 'set', 'neural', 'resource', 'easy', 'map', 'directly', 'digital', 'hardware.', 'A', 'simple', 'pattern', 'classification', 'problem', 'chosen', 'paper', 'show', 'FPNA', 'allow', 'replace', 'complex', 'standard', 'neural', 'architecture', 'hardware-friendly', 'neural', 'structures.', 'FPNA', 'apply', 'numerous', 'problem', 'similar', 'benefits.', 'They', 'apply', 'high-dimensional', 'real-world', 'applications,', 'multiband', 'speech', 'recognition.']\n",
      "abstract\\a19.txt\n",
      "\n",
      "['Recently,', 'neural', 'network', 'become', 'important', 'method', 'field', 'medical', 'diagnostics.', 'The', 'objective', 'work', 'diagnose', 'hepatitis', 'disease', 'use', 'different', 'neural', 'network', 'architectures.', 'Standard', 'feedforward', 'network', 'hybrid', 'network', 'investigated.', 'Results', 'obtain', 'show', 'especially', 'hybrid', 'network', 'successfully', 'use', 'diagnose', 'hepatitis.']\n",
      "abstract\\a2.txt\n",
      "\n",
      "['We', 'present', 'two', 'input', 'data', 'preprocessing', 'method', 'machine', 'learn', '(ML).', 'The', 'first', 'one', 'consists', 'extend', 'set', 'attribute', 'describe', 'object', 'input', 'data', 'table', 'new', 'attribute', 'second', 'one', 'consists', 'replace', 'attribute', 'new', 'attributes.', 'The', 'method', 'utilize', 'formal', 'concept', 'analysis', '(FCA)', 'boolean', 'factor', 'analysis,', 'recently', 'described', 'FCA,', 'new', 'attribute', 'define', 'so-called', 'factor', 'concept', 'compute', 'input', 'data', 'table.', 'The', 'method', 'demonstrate', 'decision', 'tree', 'induction.', 'The', 'experimental', 'evaluation', 'comparison', 'performance', 'decision', 'tree', 'induced', 'original', 'preprocessed', 'input', 'data', 'perform', 'standard', 'decision', 'tree', 'induction', 'algorithm', 'ID3', 'C4.5', 'several', 'benchmark', 'datasets.']\n",
      "abstract\\a20.txt\n",
      "\n",
      "['Routing', 'optical,', 'especially', 'wavelength', 'division', 'multiplexing', 'networks,', 'hard', 'task.', 'This', 'paper', 'defines', 'new', 'rout', 'algorithm,', 'base', 'Hopfield', 'neural', 'network.', 'It', 'improvement', 'previous', 'research,', 'apply', 'optical', 'communication']\n",
      "abstract\\a21.txt\n",
      "\n",
      "['The', 'information', 'storage', 'mechanism', 'biological', 'neural', 'network', 'important', 'problem', 'neuroscience.', 'Our', 'observation', 'show', 'structure', 'hippocampus,', 'core', 'memory', 'brain,', 'similar', \"Hopfield's\", 'neural', 'network.', 'An', 'electronic', 'neuronic', 'model', 'construct', 'simulate', 'dynamic', 'process', 'hippocampal', 'LTP', 'process.', 'The', 'kinetic', 'process', 'post', 'synaptic', 'potential', 'synaptic-synaptic', 'interaction', 'equation', 'also', 'discussed.', 'We', 'propose', 'dual', 'cod', 'theory', 'biological', 'neural', 'information', 'assume', 'messy', 'fiber', 'synaptic', 'glomerulus', 'may', 'chief', 'storage', 'medium', 'neural', 'information.', 'A', 'geometrical', 'mapping', 'N', 'dimensional', 'unitron', 'construct', 'analyse', 'distribution', 'computation', 'energy', 'trace', 'dynamic', 'locus', 'memory', 'retrieve', 'process.']\n",
      "abstract\\a22.txt\n",
      "\n",
      "['We', 'report', 'result', 'computer', 'simulation', 'learn', 'process', 'temporal', 'series', 'artificial', 'neural', 'networks.', 'In', 'simulation,', 'use', 'feedforward', 'neural', 'network', 'model', '4-layers', 'study', 'capability', 'dynamical', 'learn', 'process', 'chaotic', 'time', 'series', 'produce', 'triangular', 'maps.', 'We', 'found', 'critical', 'time', '(t/sub', 'cr/)', 'learn', 'process', 'proceeds', 'abruptly.', 'We', 'also', 'found', 'critical', 'time', '(t/sub', 'cr/)', 'shorter,', 'large', 'initial', 'deviation', 'target', 'learning.', 'We', 'provide', 'detailed', 'discussion', 'learn', 'process', 'explain', 'interest', 'phenomena,', 'new', 'order', 'parameter', 'coherency', 'introduce', 'characterize', 'processes.']\n",
      "abstract\\a23.txt\n",
      "\n",
      "['In', 'paper,', 'hybrid', 'multilayer', 'feedforward', 'neural', 'network', 'hidden', 'unit', 'define', 'fuzzy', 'reference', 'points,', 'general', 'feedback', 'learn', 'method', 'presented.', 'This', 'model', 'use', 'DSS.', 'Results', 'experiment', 'process', 'identification', 'given.', 'The', 'propose', 'model', 'able', 'overcome', 'limitation', 'conventional', 'multilayer', 'feedforward', 'neural', 'network', 'apply', 'expert', 'systems.']\n",
      "abstract\\a24.txt\n",
      "\n",
      "['The', 'recurrent', 'correlation', 'neural', 'network', 'high-capacity', 'associative', 'memory', 'weight', 'function', 'satisfies', 'certain', 'condition.', 'But', 'always', 'cause', 'high', 'dynamic', 'neural', 'network', 'hardware', 'realization', 'difficult.', 'This', 'paper', 'give', 'relationship', 'capacity', 'dynamic', 'provide', 'general', 'principle', 'choice', 'weight', 'function', 'give', 'kind', 'weight', 'function.', 'It', 'high-capacity', 'avoids', 'high', 'dynamics.', 'Finally,', 'simulated', 'result', 'given.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a25.txt\n",
      "\n",
      "['This', 'paper', 'proposes', 'new', 'branch', 'neural', 'networks,', 'call', '\"neurite', 'networks\",', 'neural', 'network', 'grows,', 'i.e.', 'embryological', 'component.', 'The', 'artificial', 'neurite', 'network', 'introduce', 'base', 'cellular', 'automaton', '(CA)', 'network', 'whose', 'branching', 'genetically', 'programmed', '(i.e.', 'grown', 'control', 'genetic', 'algorithm).', 'A', 'sequence', 'CA', 'signal', 'sent', 'middle', 'CA', '\"trail\".', 'When', 'signal', 'hit', 'end', 'trail,', 'make', 'trail', 'extend,', 'turn', 'left,', 'turn', 'right,', 'branch', 'left,', 'branch', 'right,', 'split,', 'etc.,', 'depend', 'upon', 'state', 'CA', 'signal.', 'These', 'signal', 'sequence', 'treat', 'chromosome', 'genetic', 'algorithm.', 'Once', 'CA', 'network', 'formed,', 'second', 'set', 'CA', 'state', 'transition', 'rule', 'switch', 'make', 'behave', 'like', 'neural', 'network.', 'The', 'fitness', 'CA', 'base', 'neural', 'network', 'measure', 'term', 'well', 'control', 'behavior', 'biological', 'robot.']\n",
      "abstract\\a26.txt\n",
      "\n",
      "['This', 'paper', 'proposes', 'add', 'filter', 'layer', 'dot', 'product', 'match', 'neural', 'network.', 'The', 'purpose', 'filter', 'layer', 'discard', 'unfavourable', 'choice', 'check', 'low', 'upper', 'bound', 'exemplar', 'test', 'pattern.', 'The', 'product', 'supervised,', 'fast', 'learn', 'filter', 'neural', 'network.', 'It', 'well', 'generalisation', 'capability', 'ordinary', 'dot', 'product', 'match', 'neural', 'network.', 'The', 'new', 'neural', 'network', 'test', 'speaker-independent', 'spoken', 'number', '(in', 'English)', 'recognition.', 'An', 'accuracy', '96.5%', 'report', 'test', 'data.', 'Without', 'filter', 'layer,', 'recognition', 'rate', 'fall', '94.0%.']\n",
      "abstract\\a27.txt\n",
      "\n",
      "['Discussing', 'new', 'architecture', 'high', 'performance', 'computer', 'base', 'transputers', 'dedicate', 'VLSI.', 'The', 'author', 'proposes', 'new', 'general', 'purpose', 'custom-made', 'digital', 'neurochip', 'flexible', 'implementation', 'multilayer', 'neural', 'network', 'programmable', 'bit', 'weight', 'input', 'signals.', 'The', 'neuroTRAM', 'consists', 'transputers,', 'memory', 'neurochips', 'neurocomputer', 'implementation.']\n",
      "abstract\\a28.txt\n",
      "\n",
      "['A', 'genetic', 'method', 'propose', 'optimize', 'random', 'neural', 'network', 'compose', 'asynchronous', 'thresholding', 'neural', 'units.', 'Each', 'unit', 'belongs', 'one', 'three', 'categories,', 'input', 'units,', 'hidden', 'unit', 'output', 'units,', 'kind', 'connection', 'among', 'unit', 'include', 'feedforward,', 'feedback', 'mutual', 'connection', 'allowable', 'except', 'connection', 'input', 'units.', 'Several', 'virtual', 'living', 'thing', 'whose', 'genotype', 'connection', 'among', 'neural', 'unit', 'randomly', 'generated,', 'generation', 'iteration', 'repeat', 'order', 'optimize', 'them.', 'In', 'generation', 'iteration,', 'individual', 'adequate', 'give', 'problem', 'make', 'child', 'inferior', 'one', 'remove', 'population.', 'Optimized', 'neural', 'network', 'obtain', 'evolve', 'individuals.', 'An', 'action', 'control', 'problem', 'computer', 'game', 'treat', 'application', 'method.']\n",
      "abstract\\a29.txt\n",
      "\n",
      "['The', 'traffic', 'transform', 'difficult', 'structure', 'point', 'design', 'manage', 'reason', 'increase', 'number', 'vehicle.', 'This', 'situation', 'discover', 'road', 'accident', 'problem,', 'influence', 'public', 'health', 'country', 'economy', 'do', 'study', 'solution', 'problem.', 'Large', 'calibrate', 'data', 'agglomeration', 'increase', 'reason', 'technological', 'improvement', 'data', 'storage', 'low', 'cost.', 'Arising', 'need', 'accession', 'information', 'large', 'calibrate', 'data', 'obtain', 'corner', 'stone', 'data', 'mining.', 'In', 'study,', 'assignment', 'compatible', 'machine', 'learn', 'classification', 'technique', 'road', 'accident', 'estimation', 'data', 'mining', 'intended.']\n",
      "abstract\\a3.txt\n",
      "\n",
      "['This', 'paper', 'present', 'exploratory', 'machine', 'learn', 'attack', 'base', 'deep', 'learn', 'infer', 'functionality', 'arbitrary', 'classifier', 'polling', 'black', 'box,', 'use', 'return', 'label', 'build', 'functionally', 'equivalent', 'machine.', 'Typically,', 'costly', 'time', 'consume', 'build', 'classifier,', 'require', 'collect', 'training', 'data', '(e.g.,', 'crowdsourcing),', 'select', 'suitable', 'machine', 'learn', 'algorithm', '(through', 'extensive', 'test', 'use', 'domain-specific', 'knowledge),', 'optimize', 'underlie', 'hyperparameters', '(applying', 'good', 'understand', \"classifier's\", 'structure).', 'In', 'addition,', 'information', 'typically', 'proprietary', 'protected.', 'With', 'propose', 'black-box', 'attack', 'approach,', 'adversary', 'use', 'deep', 'learn', 'reliably', 'infer', 'necessary', 'information', 'use', 'label', 'previously', 'obtain', 'classifier', 'attack,', 'build', 'functionally', 'equivalent', 'machine', 'learn', 'classifier', 'without', 'know', 'type,', 'structure', 'underlie', 'parameter', 'original', 'classifier.', 'Results', 'text', 'classification', 'application', 'demonstrate', 'deep', 'learn', 'infer', 'Naive', 'Bayes', 'SVM', 'classifier', 'high', 'accuracy', 'steal', 'functionalities.', 'This', 'new', 'attack', 'paradigm', 'deep', 'learn', 'introduces', 'additional', 'security', 'challenge', 'online', 'machine', 'learn', 'algorithm', 'raise', 'need', 'novel', 'mitigation', 'strategy', 'counteract', 'high', 'fidelity', 'inference', 'capability', 'deep', 'learning.']\n",
      "abstract\\a30.txt\n",
      "\n",
      "['Summary', 'form', 'given.', 'In', 'area', 'brain,', 'numerous', 'neuron', 'constitute', 'elaborate', 'networks.', 'These', 'network', 'link', 'numerous', 'connections,', 'compose', 'large-scaled', 'neural', 'systems.', 'The', 'neural', 'system', 'generate', 'major', 'brain', 'function', 'movement,', 'cognition,', 'emotion,', 'memory-learning.', 'The', 'brain', 'extensively', 'study', 'anatomically,', 'physiologically', 'chemically,', 'knowledge', 'ever', 'grows', 'cover', 'every', 'detail', 'brain.', 'Important', 'principle', 'activity-dependent', 'synaptic', 'plasticity,', 'multilayered', 'integration', 'neuronal', 'networks,', 'modular', 'organization', 'brain', 'tissue', 'revealed.', 'Yet,', 'shortage', 'knowledge', 'obvious', 'one', 'try', 'reproduce', 'brain', 'function', 'models.', 'While', 'simple', 'perceptron', 'model,', 'adaptive', 'filter', 'model,', 'feedforward', 'adaptive', 'control', 'system', 'model', 'successfully', 'reproduce', 'function', 'cerebellum,', 'effort', 'model', 'part', 'brain', 'met', 'great', 'difficulties.', 'It', 'still', 'difficult', 'answer', 'fundamental', 'question', 'meant', 'intricate', 'structure', 'basal', 'ganglia?', 'How', 'hippocampal', 'circuit', 'serf', 'cognitive', 'memory', 'learning?', 'How', 'language', 'encode', 'within', 'neocortical', 'network?', 'Structures', 'motor,', 'cognitive', 'emotional', 'system', 'brain', 'dissect', 'extent,', 'yet', 'difficult', 'figure', 'volition', 'emerges,', 'sense', 'beauty,', 'truth', 'virtue', 'intuitively,', 'brain', 'consciousness', 'resides.', 'Complete', 'understand', 'brain', 'could', 'achieve', 'one', 'successfully', 'model', 'neural', 'network', 'system', 'reproduce', 'entire', 'aspect', 'brain', 'functions.']\n",
      "abstract\\a31.txt\n",
      "\n",
      "['The', 'work', 'described', 'paper', 'aim', 'develop', 'neural', 'architecture', 'easy', 'map', 'onto', 'FPGA,', 'thanks', 'simplify', 'topology', 'original', 'data', 'exchange', 'scheme,', 'without', 'significant', 'loss', 'approximation', 'capability.', 'It', 'achieve', 'thanks', 'definition', 'set', 'neural', 'model', 'call', 'field', 'programmable', 'neural', 'array', '(FPNA).', 'FPNA', 'may', 'lead', 'definition', 'neural', 'network', 'adapt', 'hardware', 'topological', 'constraints.', 'Different', 'neural', 'network', 'may', 'derive', 'give', 'FPNA.', 'They', 'call', 'field', 'programmed', 'neural', 'network', '(FPNN).', 'They', 'reconcile', 'high', 'connection', 'density', 'neural', 'architecture', 'need', 'limited', 'interconnection', 'scheme', 'hardware', 'implementations.', 'This', 'paper', 'focus', 'definition', 'implementation', 'FPNN', 'parallel', 'computation.', 'It', 'briefly', 'defines', 'FPNA-FPNN', 'concept.', 'It', 'introduces', 'parallel', 'form', 'FPNN', 'computation,', 'feedforward', 'recurrent', 'FPNN.', 'It', 'describes', 'FPGA-based', 'modular', 'implementation', 'base', 'asynchronous', 'blocks.', 'A', 'result', 'FPNN', 'application', 'briefly', 'discussed.']\n",
      "abstract\\a32.txt\n",
      "\n",
      "['Presents', 'inference', 'mechanism', 'logic', 'program', 'language', 'use', 'neural', 'network', 'flexible', 'suit', 'fine-grain', 'parallel', 'computing.', 'The', 'author', 'approach', 'radically', 'different', 'conventional', 'method', 'base', 'refutation', 'processes.', 'Programs', 'write', 'logic', 'program', 'language', 'transform', 'Hopfield-type', 'neural', 'network', 'relaxation', 'technique', 'apply', 'network', 'inference', 'solutions.', 'The', 'author', 'propose', 'algorithm', 'transform', 'logic', 'program', 'Hopfield-type', 'neural', 'network', 'implement', 'prototype', 'inference', 'system', 'base', 'mechanism.', 'The', 'author', 'test', 'system', 'preliminary', 'problems.', 'Preliminary', 'result', 'confirm', 'algorithm', 'correct.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a33.txt\n",
      "\n",
      "['The', 'use', 'flash', 'device', 'analog', 'storage', 'analog', 'computation', 'result', 'highly', 'efficient', 'switched-capacitor', 'implementation', 'neural', 'networks.', 'The', 'standard', 'flash', 'device', 'suffers', 'severe', 'limitation', 'application', 'due', 'relatively', 'large', 'parasitic', 'overlap', 'capacitances.', 'This', 'paper', 'introduces', 'computational', 'concept,', 'circuit', 'architecture', 'explore', 'well', 'novel', 'flash-based', 'programmable', 'nonlinear', 'capacitor', 'much', 'improve', 'charge', 'domain', 'characteristic', 'application.', 'These', 'device', 'demonstrate', 'novel', 'circuit', 'consist', 'two', 'device', 'capable', 'compute', '5-bit', 'absolute-value-of-difference', 'energy', 'consumption', 'less', '1', 'pJ.<>']\n",
      "abstract\\a34.txt\n",
      "\n",
      "['Deep', 'Learning', 'artificial', 'intelligence', 'function', 'imitates', 'mechanism', 'human', 'mind', 'processing', 'record', 'develop', 'shape', 'use', 'selection', 'construction.', 'The', 'objective', 'paper', 'improve', 'performance', 'deep', 'learn', 'use', 'propose', 'algorithm', 'call', 'RFHTMC.', 'This', 'propose', 'algorithm', 'merge', 'version', 'Random', 'Forest', 'HTM', 'Cortical', 'Learning', 'Algorithm.', 'The', 'methodology', 'improve', 'performance', 'Deep', 'Learning', 'depends', 'concept', 'minimize', 'mean', 'absolute', 'percentage', 'error', 'indication', 'high', 'performance', 'forecast', 'procedure.', 'In', 'addition', 'overlap', 'duty', 'cycle', 'high', 'percentage', 'indication', 'speed', 'processing', 'operation', 'classifier.', 'The', 'outcome', 'depict', 'propose', 'set', 'rule', 'reduces', 'absolute', 'percent', 'error', 'use', 'half', 'value.', 'And', 'increase', 'percentage', 'overlap', 'duty', 'cycle', '15%.']\n",
      "abstract\\a35.txt\n",
      "\n",
      "['Recent', 'basic', 'study', 'reveal', 'novel', 'solution', 'fundamental', 'AI', 'problem', 'deeply', 'root', 'understand', 'natural', 'intelligence', 'maturity', 'suitable', 'mathematical', 'mean', 'rigorously', 'model', 'brain', 'machine', 'understandable', 'forms.', 'Learning', 'cognitive', 'process', 'knowledge', 'behavior', 'acquisition.', 'Learning', 'classify', 'five', 'category', 'know', 'object', 'identification,', 'cluster', 'classification,', 'functional', 'regression,', 'behavior', 'generation,', 'knowledge', 'acquisition.', 'The', 'late', 'discovery', 'knowledge', 'science', 'Wang', 'reveal', 'basic', 'unit', 'knowledge', 'binary', 'relation', '(bir)', 'bit', 'information', 'data.', 'A', 'fundamental', 'challenge', 'knowledge', 'learn', 'different', 'deep', 'recur', 'neural', 'network', 'technology', 'lead', 'emergence', 'field', 'cognitive', 'machine', 'learn', 'basis', 'recent', 'breakthrough', 'denotational', 'mathematics', 'mathematical', 'engineering.', 'This', 'keynote', 'lecture', 'present', 'late', 'advance', 'formal', 'brain', 'study', 'cognitive', 'system', 'deep', 'reason', 'deep', 'learning.', 'It', 'recognize', 'key', 'technology', 'enable', 'cognitive', 'robot', 'mimic', 'brain', 'rely', 'deep', 'learning,', 'also', 'deep', 'reason', 'think', 'towards', 'machinable', 'thought', 'cognitive', 'knowledge', 'base', 'built', 'cognitive', 'systems.', 'Fundamental', 'theory', 'novel', 'technology', 'implement', 'deep', 'think', 'robot', 'demonstrate', 'base', 'concept', 'algebra,', 'semantics', 'algebra', 'inference', 'algebra.']\n",
      "abstract\\a36.txt\n",
      "\n",
      "['Deep', 'Reinforcement', 'Learning', 'combination', 'Reinforcement', 'Learning', 'algorithm', 'Deep', 'neural', 'network,', 'recent', 'success', 'learn', 'complicate', 'unknown', 'environments.', 'The', 'train', 'model', 'Convolutional', 'Neural', 'Network', 'train', 'use', 'Q-Learning', 'Loss', 'value.', 'The', 'agent', 'take', 'observation,', 'i.e.', 'raw', 'pixel', 'image', 'reward', 'environment', 'step', 'input.', 'The', 'deep', 'Q-learning', 'algorithm', 'give', 'optimal', 'action', 'every', 'observation', 'reward', 'pair.', 'The', 'hyperparameters', 'Deep', 'Q-Network', 'remain', 'unchanged', 'environment.', 'TensorFIow,', 'open', 'source', 'machine', 'learn', 'numerical', 'computation', 'library', 'use', 'implement', 'deep', 'Q-Learning', 'algorithm', 'GPU.', 'The', 'distribute', 'TensorFIow', 'architecture', 'use', 'maximize', 'hardware', 'resource', 'utilization', 'reduce', 'training', 'time.', 'The', 'usage', 'Graphics', 'Processing', 'Unit', '(GPU)', 'distribute', 'environment', 'accelerate', 'training', 'deep', 'Q-network.', 'On', 'implement', 'deep', 'Q-learning', 'algorithm', 'many', 'environment', 'OpenAI', 'Gym,', 'agent', 'outperforms', 'decent', 'human', 'reference', 'player', 'day', 'training.']\n",
      "abstract\\a37.txt\n",
      "\n",
      "['The', 'recent', 'development', 'learn', 'deep', 'representation', 'demonstrate', 'wide', 'application', 'traditional', 'vision', 'task', 'like', 'classification', 'detection.', 'However,', 'little', 'investigation', 'could', 'build', 'deep', 'learn', 'framework', 'weakly', 'supervise', 'setting.', 'In', 'paper,', 'attempt', 'model', 'deep', 'learn', 'weakly', 'supervise', 'learn', '(multiple', 'instance', 'learning)', 'framework.', 'In', 'setting,', 'image', 'follow', 'dual', 'multi-instance', 'assumption,', 'object', 'proposal', 'possible', 'text', 'annotation', 'regard', 'two', 'instance', 'sets.', 'We', 'thus', 'design', 'effective', 'system', 'exploit', 'MIL', 'property', 'deep', 'learn', 'strategy', 'two', 'ends;', 'also', 'try', 'jointly', 'learn', 'relationship', 'object', 'annotation', 'proposals.', 'We', 'conduct', 'extensive', 'experiment', 'prove', 'weakly', 'supervise', 'deep', 'learn', 'framework', 'achieves', 'convincing', 'performance', 'vision', 'task', 'include', 'classification', 'image', 'annotation,', 'also', 'extract', 'reasonable', 'region-keyword', 'pair', 'little', 'supervision,', 'widely', 'use', 'benchmark', 'like', 'PASCAL', 'VOC', 'MIT', 'Indoor', 'Scene', '67,', 'also', 'dataset', 'image-and', 'patch-level', 'annotations.']\n",
      "abstract\\a38.txt\n",
      "\n",
      "['The', 'late', 'generation', 'Deep', 'Convolutional', 'Neural', 'Networks', '(DCNN)', 'dramatically', 'advanced', 'challenge', 'computer', 'vision', 'tasks,', 'especially', 'object', 'detection', 'object', 'classification,', 'achieve', 'state-of-the-art', 'performance', 'several', 'computer', 'vision', 'task', 'include', 'text', 'recognition,', 'sign', 'recognition,', 'face', 'recognition', 'scene', 'understanding.', 'The', 'depth', 'supervise', 'network', 'enable', 'learn', 'deeper', 'hierarchical', 'representation', 'features.', 'In', 'parallel,', 'unsupervised', 'deep', 'learn', 'Convolutional', 'Deep', 'Belief', 'Network', '(CDBN)', 'also', 'achieve', 'state-of-the-art', 'many', 'computer', 'vision', 'tasks.', 'However,', 'limited', 'research', 'jointly', 'exploit', 'strength', 'two', 'approaches.', 'In', 'paper,', 'investigate', 'learn', 'capability', 'methods.', 'We', 'compare', 'output', 'individual', 'layer', 'show', 'many', 'learnt', 'filter', 'output', 'correspond', 'level', 'layer', 'almost', 'similar', 'approaches.', 'Stacking', 'DCNN', 'top', 'unsupervised', 'layer', 'replace', 'layer', 'DCNN', 'correspond', 'learnt', 'layer', 'CDBN', 'improve', 'recognition/classification', 'accuracy', 'training', 'computational', 'expense.', 'We', 'demonstrate', 'validity', 'proposal', 'ImageNet', 'dataset.']\n",
      "abstract\\a39.txt\n",
      "\n",
      "['A', 'recent', 'work', 'introduce', 'concept', 'deep', 'dictionary', 'learning.', 'In', 'deep', 'dictionary', 'learning,', 'first', 'level', 'proceeds', 'like', 'standard', 'dictionary', 'learning;', 'sub-sequent', 'layer', '(scaled)', 'output', 'coefficient', 'previous', 'layer', 'use', 'input', 'dictionary', 'learning.', 'This', 'unsupervised', 'deep', 'learn', 'approach.', 'The', 'feature', 'final', 'deepest', 'layer', 'employ', 'subsequent', 'analysis', 'classification.', 'The', 'seminal', 'paper', 'stack', 'denoising', 'autoencoders', 'show', 'robust', 'deep', 'model', 'learnt', 'noisy', 'data', 'use', 'training', 'stack', 'autoencoders', 'instead', 'clean', 'data.', 'We', 'adopt', 'idea', 'deep', 'dictionary', 'learn', 'framework;', 'instead', 'use', 'clean', 'data', 'augment', 'training', 'dataset', 'add', 'noise;', 'improves', 'robustness.', 'Experimental', 'evaluation', 'benchmark', 'deep', 'learn', 'datasets', 'real', 'world', 'problem', 'AD', 'classification', 'show', 'proposal', 'yield', 'considerable', 'improvement.']\n",
      "abstract\\a40.txt\n",
      "\n",
      "['Summary', 'form', 'given.', 'Recent', 'basic', 'study', 'reveal', 'AI', 'problem', 'deeply', 'root', 'understand', 'natural', 'intelligence', 'adoption', 'suitable', 'mathematical', 'mean', 'rigorously', 'model', 'brain', 'machine', 'understandable', 'forms.', 'Learning', 'cognitive', 'process', 'knowledge', 'behavior', 'acquisition.', 'Learning', 'classify', 'five', 'category', 'know', 'object', 'identification,', 'cluster', 'classification,', 'functional', 'regression,', 'behavior', 'generation,', 'knowledge', 'acquisition.', 'A', 'fundamental', 'challenge', 'knowledge', 'learn', 'different', 'deep', 'recur', 'neural', 'network', 'technology', 'lead', 'emergence', 'field', 'cognitive', 'machine', 'learn', 'basis', 'recent', 'breakthrough', 'denotational', 'mathematics', 'mathematical', 'engineering.', 'This', 'keynote', 'lecture', 'present', 'late', 'advance', 'formal', 'brain', 'study', 'cognitive', 'system', 'deep', 'reason', 'deep', 'learning.', 'It', 'recognize', 'key', 'technology', 'enable', 'cognitive', 'robot', 'mimic', 'brain', 'rely', 'deep', 'learning,', 'also', 'deep', 'reason', 'think', 'towards', 'machinable', 'thought', 'cognitive', 'knowledge', 'base', 'built', 'cognitive', 'systems.', 'A', 'fundamental', 'theory', 'novel', 'technology', 'implement', 'deep', 'think', 'robot', 'demonstrate', 'base', 'concept', 'algebra,', 'semantics', 'algebra,', 'inference', 'algebra.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a41.txt\n",
      "\n",
      "['In', 'parallel', 'rapid', 'development', 'prospective', 'system', 'last', '20', 'years,', 'many', 'method', 'apply', 'field.', 'One', 'deep', 'learn', 'network', 'attract', 'interest', 'researcher', 'recent', 'years.', 'The', 'DBN', '(Deep', 'Belief', 'Network),', 'train', 'one', 'layer', 'time', 'greedily,', 'us', 'unsupervised', 'learn', 'layer', 'compose', 'RBMs', '(Restricted', 'Boltzman', 'Machine),', 'become', 'turn', 'point', 'area.', 'In', 'study,', 'deep', 'learn', 'method', 'apply', 'recommender', 'system', 'problem.', 'The', 'Python-based', 'deep', 'learn', 'library,', 'Keras,', 'use', 'exist', 'learn', 'algorithm', 'compared.']\n",
      "abstract\\a42.txt\n",
      "\n",
      "['Deep', 'Learning', 'appeal', 'learn', 'large', 'amount', 'unlabeled/unsupervised', 'data,', 'make', 'attractive', 'extract', 'meaningful', 'representation', 'pattern', 'big', 'data.', 'Deep', 'learning,', 'simplest', 'definition,', 'express', 'application', 'machine', 'learn', 'method', 'big', 'data.', 'In', 'study,', 'investigate', 'apply', 'hierarchical', 'deep', 'learn', 'model', 'problem', 'finance', 'prediction', 'classification.', 'The', 'Design', 'pricing', 'securities,', 'construction', 'portfolios,', 'risk', 'management', 'stock', 'market', 'forecasting', 'important', 'prediction', 'problem', 'finance.', 'These', 'kind', 'problem', 'include', 'large', 'data', 'set', 'complex', 'relationship', 'among', 'data', 'events.', 'It', 'difficult', 'sometimes', 'impossible', 'represent', 'complex', 'relationship', 'full', 'economic', 'model.', 'Deep', 'learn', 'methods,', 'represent', 'complex', 'relationship', 'among', 'data,', 'allows', 'production', 'useful', 'result', 'standard', 'method', 'finance.', 'In', 'study,', 'introduce', 'apply', 'deep', 'learn', 'method', 'stock', 'market', 'prediction', 'problem', 'obtain', 'successful', 'results.']\n",
      "abstract\\a43.txt\n",
      "\n",
      "['Machine', 'learning,', 'especially', 'neural', 'networks,', 'attract', 'attention', 'past', 'decades.', 'With', 'research', 'intelligent', 'algorithm', 'network', 'structures,', 'machine', 'learn', 'widely', 'use', 'data', 'mining,', 'computer', 'vision,', 'data', 'recognition', 'classification.', 'Because', 'target', 'data', 'nonlinear', 'complex,', 'research', 'need', 'extract', 'accurate', 'feature', 'space', 'data', 'space.', 'This', 'process', 'relies', 'machine', 'learn', 'perform', 'well', 'manual', 'rule', 'achieve', 'efficient', 'functions.', 'The', 'researcher', 'combine', 'kernel', 'approach', 'deep', 'neural', 'network', 'maintain', 'advantage', 'compensate', 'defects,', 'apply', 'depth', 'kernel', 'learn', 'improve', 'performance', 'algorithm.', 'In', 'paper,', 'present', 'overview', 'progress', 'application', 'deep', 'core', 'learning.', 'We', 'introduce', 'basic', 'theory', 'fusion', 'form', 'several', 'deep', 'core', 'learn', 'structure', 'improve', 'performance', 'performance', 'algorithm', 'practice.']\n",
      "abstract\\a44.txt\n",
      "\n",
      "['Recently,', 'deep', 'learn', 'emerge', 'state-of-the-art', 'approach', 'deliver', 'robust', 'highly', 'accurate', 'inference', 'many', 'domains,', 'include', 'Internet-of-Things', '(IoT).', 'Deep', 'learn', 'already', 'change', 'way', 'computer', 'embed', 'IoT', 'device', 'make', 'intelligent', 'decision', 'use', 'sensor', 'feed', 'real', 'world.', 'There', 'significant', 'effort', 'develop', 'light-weight', 'highly', 'efficient', 'deep', 'learn', 'inference', 'mechanism', 'resource-constrained', 'mobile', 'IoT', 'devices.', 'Some', 'approach', 'propose', 'hardware-based', 'accelerator,', 'approach', 'propose', 'reduce', 'amount', 'computation', 'deep', 'learn', 'model', 'use', 'various', 'model', 'compression', 'techniques.', 'Even', 'though', 'effort', 'demonstrate', 'significant', 'gain', 'performance', 'efficiency,', 'aware', 'Quality-of-Service', '(QoS)', 'requirement', 'various', 'IoT', 'applications,', 'and,', 'hence', 'manifest', 'unpredictable', \"'best-effort'\", 'performance', 'term', 'inference', 'latency,', 'power', 'consumption,', 'resource', 'usage,', 'etc.', 'In', 'IoT', 'device', 'temporal', 'constraints,', 'unpredictability', 'might', 'result', 'undesirable', 'effect', 'compromise', 'safety.', 'In', 'work,', 'present', 'novel', 'deep', 'learn', 'inference', 'runtime', 'called,', 'DeepRT.', 'Unlike', 'previous', 'inference', 'accelerators,', 'DeepRT', 'focus', 'support', 'predictable', 'inference', 'performance', 'temporally', 'spatially.']\n",
      "abstract\\a45.txt\n",
      "\n",
      "['In', 'paper,', 'introduce', 'distribute', 'deep', 'learn', 'platform,', 'BAIPAS,', 'Big', 'Data', 'AI', 'base', 'Predication', 'Analysis', 'System.', 'In', 'case', 'deep', 'learn', 'use', 'big', 'data,', 'take', 'much', 'time', 'train', 'data.', 'To', 'reduce', 'training', 'time,', 'method', 'us', 'distribute', 'deep', 'learning.', 'When', 'big', 'data', 'exists', 'external', 'storage,', 'training', 'take', 'long', 'time', 'take', 'lot', 'network', 'I/O', 'time', 'data', 'load', 'deep', 'learn', 'operations.', 'We', 'propose', 'data', 'locality', 'management', 'way', 'reduce', 'training', 'time', 'big', 'data.', 'BAIPAS', 'distribute', 'deep', 'learn', 'platform', 'aim', 'provide', 'quick', 'learn', 'big', 'data,', 'easy', 'installation', 'monitoring', 'platform,', 'convenience', 'developer', 'deep', 'learn', 'models.', 'In', 'order', 'provide', 'fast', 'training', 'use', 'big', 'data,', 'data', 'distribute', 'store', 'worker-server', 'storage', 'use', 'data', 'locality', 'shuffling,', 'training', 'performed.', 'The', 'data', 'locality', 'manager', 'analyzes', 'training', 'data', 'state', 'information', 'worker', 'servers.', 'This', 'distributes', 'data', 'schedule', 'accord', 'available', 'storage', 'space', 'worker', 'server', 'learn', 'performance', 'worker', 'server.', 'However,', 'worker', 'server', 'conduct', 'deep', 'learn', 'use', 'distribute', 'training', 'data,', 'model', 'overfitting', 'may', 'occur', 'compare', 'method', 'learn', 'full', 'training', 'data', 'set.', 'To', 'solve', 'problem,', 'apply', 'shuffle', 'method', 'move', 'already', 'learn', 'data', 'another', 'worker', 'server', 'training', 'performed.', 'Thereby,', 'worker', 'server', 'contain', 'full', 'training', 'data', 'set.', 'BAIPAS', 'us', 'Kubernetes', 'Docker', 'provide', 'easy', 'installation', 'monitoring', 'platform.', 'It', 'also', 'provide', 'pre-processing', 'modules,', 'management', 'tools,', 'automation', 'cluster', 'creation,', 'resource', 'monitoring,', 'resources;', 'developer', 'easily', 'develop', 'deep', 'learn', 'models.']\n",
      "abstract\\a46.txt\n",
      "\n",
      "['SARSA,', 'one', 'kind', 'on-policy', 'reinforcement', 'learn', 'methods,', 'integrate', 'deep', 'learn', 'solve', 'video', 'game', 'control', 'problem', 'paper.', 'We', 'use', 'deep', 'convolutional', 'neural', 'network', 'estimate', 'state-action', 'value,', 'SARSA', 'learn', 'update', 'it.', 'Besides,', 'experience', 'replay', 'introduce', 'make', 'training', 'process', 'suitable', 'scalable', 'machine', 'learn', 'problems.', 'In', 'way,', 'new', 'deep', 'reinforcement', 'learn', 'method,', 'call', 'deep', 'SARSA', 'propose', 'solve', 'complicate', 'control', 'problem', 'imitate', 'human', 'play', 'video', 'games.', 'From', 'experiment', 'results,', 'conclude', 'deep', 'SARSA', 'learn', 'show', 'well', 'performance', 'aspect', 'deep', 'Q', 'learning.']\n",
      "abstract\\a47.txt\n",
      "\n",
      "['Deep', 'learn', 'propose', 'Hinton', 'et', 'al', 'new', 'learn', 'algorithm', 'multi-layer', 'neural', 'network,', 'also', 'new', 'study', 'field', 'machine', 'learning.', 'This', 'paper', 'describes', 'structure', 'advantage', 'shallow', 'learn', 'deep', 'learning,', 'analyzes', 'current', 'popular', 'learn', 'algorithm', 'detail.', 'Finally,', 'paper', 'analyzes', 'research', 'direction', 'future', 'prospect', 'deep', 'learning.']\n",
      "abstract\\a48.txt\n",
      "\n",
      "['A', 'promising', 'direction', 'deep', 'learn', 'research', 'learn', 'representation', 'simultaneously', 'discover', 'cluster', 'structure', 'unlabeled', 'data', 'optimize', 'discriminative', 'loss', 'function.', 'Contrary', 'supervise', 'deep', 'learning,', 'line', 'research', 'infancy', 'design', 'optimization', 'suitable', 'loss', 'function', 'aim', 'training', 'deep', 'neural', 'network', 'cluster', 'still', 'open', 'challenge.', 'In', 'paper,', 'propose', 'leverage', 'discriminative', 'power', 'information', 'theoretic', 'divergence', 'measures,', 'experienced', 'success', 'traditional', 'clustering,', 'develop', 'new', 'deep', 'cluster', 'network.', 'Our', 'propose', 'loss', 'function', 'incorporates', 'explicitly', 'geometry', 'output', 'space,', 'facilitates', 'fully', 'unsupervised', 'training', 'end-to-end.', 'Experiments', 'real', 'datasets', 'show', 'propose', 'algorithm', 'achieves', 'competitive', 'performance', 'respect', 'state-of-the-art', 'methods.']\n",
      "abstract\\a5.txt\n",
      "\n",
      "['The', 'traditional', 'SVM', 'support', 'incremental', 'learning.', 'And', 'traditional', 'training', 'method', 'SVM', 'work', 'amount', 'training', 'sample', 'large', 'put', 'RAM', 'computer.', 'In', 'order', 'solve', 'problem', 'improve', 'speed', 'training', 'SVM,', 'natural', 'characteristic', 'SV', 'analyze', 'paper.', 'An', 'incremental', 'learn', 'algorithm', '(I-SVM)', 'SVM', 'discard', 'part', 'history', 'sample', 'presented.', 'The', 'theoretical', 'analysis', 'experimental', 'result', 'show', 'algorithm', 'speed', 'training', 'process,', 'also', 'reduce', 'storage', 'cost,', 'classification', 'precision', 'also', 'guaranteed.']\n",
      "abstract\\a50.txt\n",
      "\n",
      "['Deep', 'architecture', 'convolution', 'structure', 'found', 'highly', 'effective', 'commonly', 'use', 'computer', 'vision.', 'With', 'introduction', 'Graphics', 'Processing', 'Unit', '(GPU)', 'general', 'purpose', 'issues,', 'increase', 'attention', 'towards', 'exploit', 'GPU', 'processing', 'power', 'deep', 'learn', 'algorithms.', 'Also,', 'large', 'amount', 'data', 'online', 'make', 'possible', 'train', 'deep', 'neural', 'network', 'efficiently.', 'The', 'aim', 'paper', 'perform', 'systematic', 'mapping', 'study,', 'order', 'investigate', 'exist', 'research', 'implementation', 'computer', 'vision', 'approach', 'base', 'deep', 'learn', 'algorithm', 'Convolutional', 'Neural', 'Networks', '(CNN).', 'We', 'select', 'total', '119', 'papers,', 'classify', 'accord', 'field', 'interest,', 'network', 'type,', 'learn', 'paradigm,', 'research', 'contribution', 'type.', 'Our', 'study', 'demonstrates', 'field', 'promising', 'area', 'research.', 'We', 'choose', 'human', 'pose', 'estimation', 'video', 'frame', 'possible', 'computer', 'vision', 'task', 'explore', 'research.', 'After', 'careful', 'study', 'propose', 'three', 'different', 'research', 'direction', 'related', 'to:', 'improve', 'exist', 'CNN', 'implementations,', 'use', 'Recurrent', 'Neural', 'Networks', '(RNNs)', 'human', 'pose', 'estimation', 'finally', 'rely', 'unsupervised', 'learn', 'paradigm', 'train', 'NNs.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a51.txt\n",
      "\n",
      "['This', 'paper', 'discus', 'emergence', 'cooperative', 'coordinate', 'behavior', 'joint', 'concurrent', 'learn', 'agent', 'use', 'deep', 'Q-learning.', 'Multi-agent', 'system', '(MAS)', 'arise', 'variety', 'domains.', 'The', 'collective', 'effort', 'one', 'main', 'building', 'block', 'many', 'fundamental', 'system', 'exist', 'world,', 'thus,', 'sequential', 'decision', 'make', 'uncertainty', 'collaborative', 'work', 'one', 'important', 'challenge', 'issue', 'intelligent', 'cooperative', 'multiple', 'agents.', 'However,', 'decision', 'cooperation', 'highly', 'sophisticated', 'complicate', 'agent', 'may', 'certain', 'share', 'goal', 'individual', 'goal', 'achieve', 'behavior', 'inevitably', 'influence', 'other.', 'Therefore,', 'attempt', 'explore', 'whether', 'agent', 'use', 'deep', 'Q-networks', '(DQN)', 'learn', 'cooperative', 'behavior.', 'We', 'use', 'double', 'pong', 'game', 'example', 'investigate', 'learn', 'divide', 'work', 'iterate', 'game', 'executions.', 'In', 'approach,', 'agent', 'jointly', 'learn', 'divide', 'area', 'responsibility', 'agent', 'us', 'DQN', 'modify', 'behavior.', 'We', 'also', 'investigate', 'learn', 'behavior', 'change', 'accord', 'environmental', 'characteristic', 'include', 'reward', 'scheme', 'learn', 'techniques.', 'Our', 'experiment', 'indicate', 'effective', 'cooperative', 'behavior', 'balance', 'division', 'workload', 'emerge.', 'These', 'result', 'help', 'u', 'well', 'understand', 'agent', 'behave', 'interact', 'complex', 'environment', 'coherently', 'choose', 'individual', 'action', 'result', 'joint', 'action', 'optimal.']\n",
      "abstract\\a52.txt\n",
      "\n",
      "['Deep', 'Belief', 'Network', 'algorithm', 'among', 'deep', 'learning.', 'It', 'effective', 'method', 'solve', 'problem', 'neural', 'network', 'deep', 'layers,', 'low', 'velocity', 'overfitting', 'phenomenon', 'learning.', 'In', 'paper,', 'introduce', 'process', 'Deep', 'Belief', 'Network', 'use', 'Restricted', 'Boltzmann', 'Machines.', 'What', 'more,', 'combine', 'Deep', 'Belief', 'Network', 'together', 'softmax', 'classifier,', 'use', 'recognition', 'handwritten', 'numbers.']\n",
      "abstract\\a53.txt\n",
      "\n",
      "['Hand', 'gesture', 'recognition', 'one', 'major', 'research', 'area', 'field', 'Human', 'computer', 'interaction', '(HCl).', 'This', 'paper', 'proposes', 'deep', 'reinforcement', 'learn', 'algorithm', 'recognize', 'human', 'arm', 'movement', 'pattern', 'use', 'IoT', 'sensor', 'device.', 'Recent', 'study', 'explore', 'supervise', 'learn', 'base', 'methods,', 'CNN', 'RNN', 'implement', 'HCl', 'device.', 'On', 'hand,', 'deep', 'reinforcement', 'learn', 'approach', 'also', 'investigated.', 'Algorithms', 'use', 'approach,', 'learn', 'pattern', 'sensor', 'use', 'reward', 'feedback', 'class', 'labels.', 'This', 'allows', 'user', 'control', 'IoT', 'device', 'produce', 'desire', 'arm', 'movement', 'pattern', 'without', 'create', 'labels.', 'In', 'paper,', 'performance', 'convolutional', 'neural', 'network', '(CNN)', 'DQN', 'model', 'compare', 'long', 'short-term', 'memory', '(LSTM)', 'model', 'DQN.', 'Results', 'show', 'CNN', 'base', 'DQN', 'model', 'stable', 'compare', 'LSTM', 'base', 'model,', 'yield', 'high', 'classification', 'accuracy', '98.33%', 'predict', 'arm', 'movement', 'patterns.']\n",
      "abstract\\a54.txt\n",
      "\n",
      "['This', 'paper', 'introduces', 'new', 'surveillance', 'platform', 'equip', 'multiple', 'parallel', 'deep', 'learn', 'frameworks.', 'The', 'deep', 'learn', 'framework', 'use', 'face', 'recognition', 'input', 'image', 'video', 'stream', 'CCTV', 'camera', 'security', 'applications.', 'Each', 'deep', 'learn', 'framework', 'accuracy', '(related', 'recognition', 'performance)', 'operation', 'time', '(related', 'system', 'stability)', 'tradeoff', 'relationship.', 'Based', 'system', 'architecture,', 'new', 'dynamic', 'control', 'algorithm', 'selects', 'one', 'deep', 'learn', 'framework', 'time-average', 'security-level', '(i.e.,', 'machine', 'learn', 'accuracy', 'recognition', 'classification)', 'maximization', 'consideration', 'system', 'stability.', 'The', 'performance', 'propose', 'algorithm', 'evaluate', 'also', 'verify', 'achieves', 'desire', 'performance.']\n",
      "abstract\\a55.txt\n",
      "\n",
      "['High-performance', 'I/O', 'essential', 'big-data', 'analyses.', 'Modern', 'storage', 'system', 'utilize', 'HDDs', 'SSDs', 'mainly', 'achieve', 'large', 'capacity', 'high', 'performance,', 'respectively.', 'Using', 'SSD', 'cache', 'access', 'HDDs', 'one', 'promising', 'method', 'improve', 'large-scale', 'I/O', 'performance', 'modern', 'computers.', 'In', 'addition,', 'M.2', 'increase', 'importance', 'high-performance', 'I/O', 'processing.', 'In', 'paper,', 'investigate', 'I/O', 'performance', 'storage', 'system', 'include', 'M.2', 'SSD', 'SSD', 'cache.', 'Our', 'experimental', 'result', 'show', 'big-data', 'processing', 'performance', 'improve', 'significantly', 'use', 'M.2', 'SSD', 'cache']\n",
      "abstract\\a56.txt\n",
      "\n",
      "['propose', 'two', 'new', 'method', 'accelerate', 'learn', 'task', 'use', 'Q-learning', 'algorithm.', 'We', 'focus', 'specifically', 'learn', 'task,', 'Credit', 'Assignment', '(CA)', 'problem.', 'A', 'Reinforcement', 'Algorithm', '(RL)', 'agent', 'perform', 'task', 'high', 'dimensional', 'state-space.', 'The', 'main', 'idea', 'paper', 'use', 'latent', 'variable', 'deep', 'autoencoders', 'provide,', 'make', 'well', 'reward', 'system.', 'We', 'show', 'use', 'new', 'reward', 'speed', 'learn', 'task', 'similar', 'circumstances.', 'The', 'task', 'chosen', 'algorithm', 'Push', 'Recovery', '(PR)', 'simulated', 'environment.']\n",
      "abstract\\a57.txt\n",
      "\n",
      "['Recently,', 'grow', 'interest', 'apply', 'deep', 'learn', 'game', 'AI', 'domain.', 'Among', 'them,', 'deep', 'reinforcement', 'learn', 'famous', 'game', 'AI', 'communities.', 'In', 'paper,', 'propose', 'use', 'redundant', 'output', 'order', 'adapt', 'training', 'progress', 'deep', 'reinforcement', 'learning.', 'We', 'compare', 'method', 'general', 'Îµ-greedy', 'ViZDoom', 'platform.', 'Since', 'AI', 'player', 'select', 'action', 'base', 'visual', 'input', 'platform,', 'suitable', 'deep', 'reinforcement', 'learn', 'research.', 'Experimental', 'result', 'show', 'propose', 'method', 'archive', 'competitive', 'performance', 'Îµ-greedy', 'without', 'parameter', 'tuning.']\n",
      "abstract\\a58.txt\n",
      "\n",
      "['Summary', 'form', 'given,', 'follows.', 'The', 'author', 'describes', 'recent', 'advance', 'hardware', 'implementation', 'neural', 'networks,', 'give', 'expectation', 'future', 'aspect', 'neural', 'network', 'technology.<>']\n",
      "abstract\\a59.txt\n",
      "\n",
      "['Proposes', 'extend', 'bidirectional', 'associative', 'memory', '(BAM)', 'neural', 'network', 'model', 'auto-', 'hetero-associative', 'memory.', 'The', 'theoretical', 'proof', 'neural', 'network', \"model's\", 'stability', 'given.', 'Experiments', 'show', 'neural', 'network', 'model', 'much', 'powerful', 'M-P', 'model,', 'discrete', 'Hopfield', 'neural', 'network,', 'continuous', 'Hopfield', 'neural', 'network,', 'discrete', 'bidirectional', 'associative', 'memory', 'neural', 'network,', 'continuous', 'adaptive', 'bidirectional', 'associative', 'memory', 'neural', 'network,', 'backpropagation', 'neural', 'network', 'optimal', 'design', 'nonlinear', 'continuous', 'neural', 'network.', 'Experimental', 'result', 'also', 'show', 'that,', 'auto-associative', 'memory,', 'power', 'model', 'loop', 'neural', 'network', 'model', 'auto-associative', 'memory.']\n",
      "abstract\\a6.txt\n",
      "\n",
      "['The', 'theory', 'machine', 'learn', 'metric', 'space', 'new', 'research', 'topic', 'drawn', 'much', 'attention', 'recent', 'years.', 'The', 'theoretical', 'foundation', 'topic', 'question', 'condition', 'two', 'sample', 'set', 'separate', 'space.', 'In', 'paper,', 'motivate', 'develop', 'new', 'support', 'vector', 'machine', '(SVM)', 'fuzzy', 'number', 'space,', 'present', 'necessary', 'sufficient', 'condition', 'separate', 'two', 'finite', 'class', 'sample', 'hyper-plane', 'n-dimensional', 'fuzzy', 'number', 'space.', 'We', 'also', 'present', 'attainable', 'expression', 'maximal', 'margin', 'separate', 'hyper-planes', 'include', 'case', 'class', 'infinite', 'sample', 'n-dimensional', 'fuzzy', 'number', 'space.', 'These', 'result', 'generalize', 'improve', 'correspond', 'conclusion', 'theory', 'SVM', 'Hilbert', 'space', 'fuzzy', 'number', 'space.']\n",
      "abstract\\a60.txt\n",
      "\n",
      "['FEN', '(fuzzy', 'expert', 'network)', 'new', 'network', 'architecture', 'neural', 'object', 'fuzzy', 'modeling.', 'The', 'neural', 'object', 'process', 'information', 'node', 'function', 'different', 'typical', 'sigmoidal', 'node', 'processor', 'analog', 'perceptron.', 'By', 'connect', 'type', 'node', 'processor', 'event', 'driven', 'acyclic', '(feedforward)', 'neural', 'network,', 'FEN', 'represent', 'fuzzy', 'model', 'self', 'adjustment.', 'Weights', 'network', 'imply', 'fuzzy', 'parameter', 'adjust', 'restriction', 'layer', 'topology', 'learning.', 'FEN', 'offer', 'automate', 'tune', 'input-output', 'data', 'membership', 'function', 'performance', 'fuzzy', 'model', 'depends.', 'And', 'especially', 'use', 'enhance', 'idea', 'dynamic', 'backward', 'error', 'assignment', 'learning,', 'FEN', 'effective', 'tune', 'parameter', 'nonsmooth', 'membership', 'functions,', 'example,', 'symmetric', 'triangular', 'function', 'antecedent', 'part.', 'Results', 'test', 'FEN', 'present', 'demonstrate', 'learn', 'performance', 'adaptability.']\n",
      "abstract\\a61.txt\n",
      "\n",
      "['In', 'paper,', 'describe', 'VLSI', 'implementation', 'modify', 'backpropagation', 'learn', 'T-Model', 'neural', 'networks.', 'A', 'digitally-controlled', 'synapse', 'circuit', 'adaptation', 'rule', 'circuit', 'R-2R', 'ladder', 'network,', 'simple', 'control', 'logic', 'circuit', 'UP/DOWN', 'counter', 'implement', 'realize', 'modify', 'backpropagation', 'error', 'technique.', 'We', 'also', 'present', 'adaptive', 'learn', 'use', 'digitally-controlled', 'synapse', 'T-Model', 'network', 'several', 'example', 'order', 'study', 'learn', 'capability', 'analog', 'T-Model', 'neural', 'hardware.', 'These', 'experiment', 'show', 'T-Model', 'adaptive', 'neural', 'network', 'use', 'modify', 'backpropagation', 'perform', 'learn', 'procedure', 'quite', 'well.']\n",
      "abstract\\a62.txt\n",
      "\n",
      "['Subthreshold', 'analog', 'circuit', 'MOS', 'implementation', 'artificial', 'neural', 'network', 'present', 'on-chip', 'learn', 'capability.', 'Each', 'synapse', 'circuit', 'consist', 'storage', 'capacitor', '3', 'analog', 'multiplier,', 'i.e.', 'one', 'signal', 'feedforward,', 'one', 'outer-product', 'synaptic', 'weight', 'adjustments,', 'one', 'error', 'backpropagation.', 'While', '3', 'multiplier', 'use', 'error', 'backpropagation', 'learning,', 'first', '2', 'multiplier', 'use', 'Hebbian', 'learning.', 'Each', 'neuron', 'circuit', 'compose', 'sigmoid', 'circuit', 'sigmoid', 'derivative', 'circuit,', 'show', 'near', 'ideal', 'sigmoid', 'characteristic', 'provide', 'external', 'gain-control', 'capability.', 'All', 'circuit', 'incorporate', 'modular', 'architecture,', 'design', 'increase', 'number', 'neuron', 'layer', 'multiple', 'chips.', 'Also,', 'subthreshold', 'operation', 'provide', 'low', 'power', 'consumption', 'large', 'scale', 'implementation.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a63.txt\n",
      "\n",
      "['Summary', 'form', 'given,', 'follows.', 'A', 'Hopfield', 'model', 'neural', 'network', 'useful', 'form', 'parallel', 'computer.', 'Such', 'neural', 'network', 'may', 'capable', 'arrive', 'problem', 'solution', 'much', 'speed', 'conventional,', 'sequential', 'approaches.', 'This', 'concept', 'apply', 'problem', 'generate', 'control', 'bit', 'multistage', 'interconnection', 'network.', 'A', 'Hopfield', 'model', 'neural', 'network', 'design', 'capable', 'rout', 'set', 'messages.', 'This', 'neural', 'network', 'solution', 'especially', 'useful', 'interconnection', 'network', 'self-routing', 'interconnection', 'network', 'irregular', 'structure.', 'Furthermore,', 'neural', 'network', 'rout', 'scheme', 'fault-tolerant.', 'Results', 'obtain', 'generate', 'route', '4*4', 'Benes', 'interconnection', 'network.<>']\n",
      "abstract\\a64.txt\n",
      "\n",
      "['A', 'disturbance-rejection', 'neural', 'network', 'control', 'scheme', 'present', 'control', 'unknown', 'nonlinear', 'plant.', 'In', 'scheme,', 'multilayer', 'neural', 'network', 'employ', 'learn', 'inverse', 'dynamic', 'unknown', 'plant', 'act', 'feedforward', 'controller', 'control', 'plant.', 'The', 'effect', 'disturbance', 'output', 'suppress', 'use', 'parallel', 'closed-loop', 'control', 'system.', 'The', 'design', 'technique', 'compensator', 'closed-loop', 'system', 'discussed.', 'Simulation', 'result', 'show', 'present', 'control', 'scheme', 'work', 'well', 'presence', 'disturbances.']\n",
      "abstract\\a65.txt\n",
      "\n",
      "['A', 'method', 'use', 'artificial', 'neural', 'network', 'stabilize', 'large', 'flexible', 'space', 'structure', 'presented.', 'The', 'neural', 'controller', 'learns', 'dynamic', 'structure', 'control', 'construct', 'control', 'signal', 'stabilize', 'structural', 'vibrations.', 'The', 'network', 'consists', 'three', 'layer', 'feedforward', 'network;', 'input', 'layer', 'receives', 'displacement', 'velocity', 'information', 'sensor', 'locate', 'various', 'point', 'structure,', 'output', 'layer', 'generates', 'control', 'signal', 'apply', 'structure', 'suitable', 'actuators.', 'Sequential', 'update', 'network', 'weight', 'continues,', 'force', 'structure', 'follow', 'trajectory', 'eventually', 'lead', 'complete', 'stabilization.', 'Simulation', 'result', 'stabilization', 'flexible', 'beam', 'presented.']\n",
      "abstract\\a66.txt\n",
      "\n",
      "['In', 'paper,', 'propose', 'approximate', 'equivalence', 'neural', 'network', 'model', 'fast', 'learn', 'speed', 'well', 'good', 'function', 'approximation', 'capability,', 'new', 'objective', 'function,', 'satisfies', 'H/sup', '/spl', 'infin//', 'induced', 'norm', 'solve', 'worst-case', 'identification', 'control', 'nonlinear', 'problems.', 'The', 'approximate', 'equivalence', 'neural', 'network', 'capability', 'universal', 'approximator,', 'also', 'faster', 'learn', 'speed', 'conventional', 'feedforward/recurrent', 'neural', 'networks.', 'Based', 'approximate', 'transformable', 'technique,', 'relationship', 'single-layered', 'neural', 'network', 'multilayered', 'perceptrons', 'neural', 'network', 'derived.', 'It', 'show', 'approximate', 'equivalence', 'neural', 'network', 'represent', 'functional', 'link', 'network', 'base', 'Chebyshev', 'polynomials.', 'We', 'also', 'derive', 'new', 'learn', 'algorithm', 'infinity', 'norm', 'transfer', 'function', 'input', 'output', 'prescribed', 'level.', 'It', 'turn', 'approximate', 'equivalence', 'neural', 'network', 'extend', 'worst-case', 'problem,', 'identification', 'control', 'nonlinear', 'problems.']\n",
      "abstract\\a67.txt\n",
      "\n",
      "['It', 'necessary', 'introduce', 'many', 'parameter', 'describe', 'structure', 'input', 'signal', 'pattern', 'recognition', 'system', 'construction', 'open-loop', 'structure', 'multilayer', 'neural', 'network', 'order', 'provide', 'maximum', 'probability', 'correct', 'recognition', 'practice.', 'Availability', 'great', 'number', 'parameters,', 'viz.', 'hundred', 'thousands,', 'rous', 'difficulty', 'learn', 'technical', 'implementation', 'multilayer', 'neural', 'network.', 'Essence', 'introduction', 'continual', 'property', 'multilayer', 'neural', 'network', 'characteristic', 'include', 'following:', 'vector', '{x/sub', 'i/,', 'i=1,', '...,', 'I}', 'replaces', 'function', 'x(i)', 'continued', 'argument,', 'i.e.', 'transition', 'continuum', 'characteristic', 'value.', 'Transition', 'attribute', 'continuum', 'continuum', 'neuron', 'layer', 'consider', 'concrete', 'example', 'neural', 'network', 'structures.']\n",
      "abstract\\a68.txt\n",
      "\n",
      "['Modern', 'electronic', 'warfare', 'system', 'must', 'judge', 'threat', 'degree', 'come', 'radio', 'emitter', 'correctly', 'order', 'counter', 'limited', 'jamming', 'resource', 'effectively.', 'This', 'article', 'put', 'forward', 'new', 'strategy', 'judge', 'radio', 'emitter', 'threat', 'degree', '(RETD)', 'base', 'machine', 'learning.', 'It', 'firstly', 'get', 'membership', 'degree', 'input', 'data.', 'Then', 'input', 'data', 'classified.', 'A', 'train', 'fuzzy', 'neural', 'network', '(FNN)', 'approach', 'ability', 'give', 'threat', 'degree.', 'The', 'RETD', 'judgment', 'rule', 'could', 'mine', 'network.', 'The', 'correctness', 'effectiveness', 'prove', 'experiment.']\n",
      "abstract\\a69.txt\n",
      "\n",
      "['Total', 'knee', 'arthroplasty', '(TKA)', 'one', 'common', 'knee', 'surgeries.', 'Because', 'type', 'TKA', 'implant,', 'hard', 'select', 'appropriate', 'type', 'TKA', 'implant', 'individual', 'patient.', 'For', 'sake', 'pre-operative', 'planning,', 'study', 'present', 'novel', 'approach,', 'predicts', 'post-operative', 'implant', 'knee', 'function', 'individuals.', 'It', 'base', 'clinical', 'big', 'data', 'analysis.', 'The', 'big', 'data', 'compose', 'set', 'pre-operative', 'knee', 'mobility', 'function', 'post-operative', 'knee', 'function.', 'The', 'method', 'construct', 'post-operative', 'knee', 'function', 'prediction', 'model', 'mean', 'machine', 'learn', 'approach.', 'It', 'extract', 'feature', 'use', 'principal', 'component', 'analysis,', 'construct', 'mapping', 'function', 'pre-operative', 'feature', 'space', 'post-operative', 'feature', 'space.', 'The', 'method', 'validate', 'apply', 'prediction', 'post-operative', 'anterior-posterior', 'translation', '52', 'TKA', 'operate', 'knees.', 'Leave-one-out', 'cross', 'validation', 'test', 'reveal', 'prediction', 'performance', 'mean', 'correlation', 'coefficient', '0.79', 'mean', 'root-mean-squared-error', '3.44', 'mm.']\n",
      "abstract\\a7.txt\n",
      "\n",
      "['Based', 'statistical', 'learn', 'theory', '(SLT),', 'support', 'vector', 'machine', '(SVM),', 'new', 'kind', 'machine', 'learn', 'method', 'use', 'classification', 'regression.', 'SVM', 'consider', 'two', 'layer', 'learn', 'machine', 'since', 'map', 'original', 'space', 'high', 'dimensional', 'feature', 'space,', 'i.e.,', 'input', 'layer', 'high', 'dimensional', 'feature', 'space', 'layer.', 'If', 'high', 'dimensional', 'feature', 'space', 'layer', 'consider', 'new', \"problem's\", 'input', 'layer', 'new', 'problem', 'also', 'solve', 'SVM,', 'new', 'problem', 'solve', 'SVMs', 'name', 'multi-layer', 'SVM', '(MLSVM).', 'MLSVM', 'compose', 'input', 'layer', 'least', 'one', 'layer', 'high', 'dimensional', 'feature', 'space', 'layer.', 'In', 'paper,', 'm-th', 'order', 'ordinary', 'differential', 'equation', 'solve', 'MLSVM', 'regression.', 'Experimental', 'result', 'indicate', 'MLSVM', 'effectively', 'solve', 'problem', 'ordinary', 'differential', 'equations.', 'Thus,', 'MLSVM', 'exhibit', 'great', 'potential', 'solve', 'complex', 'problem']\n",
      "abstract\\a70.txt\n",
      "\n",
      "['Executing', 'Big', 'Data', 'workload', 'upon', 'High', 'Performance', 'Computing', '(HPC)', 'infrastractures', 'become', 'attractive', 'way', 'improve', 'performances.', 'However,', 'collocation', 'HPC', 'Big', 'Data', 'workload', 'easy', 'task,', 'mainly', 'core', \"concepts'\", 'differences.', 'This', 'paper', 'focus', 'challenge', 'related', 'schedule', 'Big', 'Data', 'HPC', 'workload', 'compute', 'platform.', 'In', 'classic', 'HPC', 'workloads,', 'rigidity', 'job', 'tends', 'create', 'hole', 'schedule:', 'use', 'idle', 'resource', 'dynamic', 'pool', 'Big', 'Data', 'workloads.', 'We', 'propose', 'new', 'idea', 'base', 'Resource', 'Job', 'Management', \"System's\", '(RJMS)', 'configuration,', 'make', 'HPC', 'Big', 'Data', 'system', 'communicate', 'simple', 'prolog/epilog', 'mechanism.', 'It', 'leverage', 'built-in', 'resilience', 'Big', 'Data', 'frameworks,', 'minimize', 'disturbance', 'HPC', 'workloads.', 'We', 'present', 'first', 'study', 'approach,', 'use', 'production', 'RJMS', 'middleware', 'OAR', 'Hadoop', 'YARN', 'HPC', 'Big', 'Data', 'ecosystem', 'respectively.', 'Our', 'new', 'technique', 'evaluate', 'real', 'experiment', 'upon', 'Grid5000', 'platform.', 'Our', 'experiment', 'validate', 'assumption', 'show', 'promising', 'results.', 'The', 'system', 'capable', 'run', 'HPC', 'workload', '70%', 'cluster', 'utilization,', 'Big', 'Data', 'workload', 'fill', 'schedule', 'hole', 'reach', 'full', '100%', 'utilization.', 'We', 'observe', 'penalty', 'mean', 'wait', 'time', 'HPC', 'job', 'less', '17%', 'Big', 'Data', 'effectiveness', '68%', 'average.']\n",
      "abstract\\a71.txt\n",
      "\n",
      "['Due', 'limited', 'technical', 'social', 'resources,', 'many', 'physician', 'practice', 'fall', 'short', 'accurate', 'blood', 'pressure', 'measurement', 'carry', 'large-scale', 'hypertension', 'research', 'projects.', 'The', 'accuracy', 'standard', 'data', 'acquisition', 'important', 'data', 'source', 'diverse', 'medical', 'big', 'data', 'research.', 'This', 'paper', 'proposes', 'Massive', 'Online', 'Open', 'Course', '(MOOC)', 'appropriate', 'approach', 'teach', 'volunteer', 'necessary', 'knowledge', 'skill', 'blood', 'pressure', 'measurement', 'hypertension', 'research.', 'It', 'introduces', 'new', 'citizen', 'science', '\"paradigm\"', 'support', 'big', 'data', 'research', 'hypertension.', 'MOOC', 'new', 'type', 'online', 'course', 'provide', 'combination', 'short', 'video', 'lectures,', 'frequent', 'comprehension', 'quiz', 'active', 'participation', 'discussion', 'forum.', 'The', 'well-trained', 'data', 'collector', 'MOOC', 'grant', 'collect', 'publish', 'data', 'hypertension', 'research.', 'The', 'process', 'medical', 'big', 'data', 'research', 'base', 'MOOC', 'introduced.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a72.txt\n",
      "\n",
      "['A', 'USAF', 'sponsor', 'MITRE', 'research', 'team', 'undertook', 'four', 'separate,', 'domain-specific', 'case', 'study', 'Big', 'Data', 'applications.', 'Those', 'case', 'study', 'initial', 'investigation', 'question', 'whether', 'data', 'quality', 'issue', 'encounter', 'Big', 'Data', 'collection', 'substantially', 'different', 'cause,', 'manifestation,', 'detection', 'data', 'quality', 'issue', 'encounter', 'traditionally', 'size', 'data', 'collections.', 'The', 'study', 'address', 'several', 'factor', 'affect', 'Big', 'Data', 'Quality', 'multiple', 'levels,', 'include', 'collection,', 'processing,', 'storage.', 'Though', 'unexpected,', 'key', 'finding', 'study', 'reinforce', 'primary', 'factor', 'affect', 'Big', 'Data', 'reside', 'limitation', 'complexity', 'involve', 'handle', 'Big', 'Data', 'maintain', 'integrity.', 'These', 'concern', 'high', 'magnitude', 'provenance', 'data,', 'processing,', 'tool', 'use', 'prepare,', 'manipulate,', 'store', 'data.', 'Data', 'quality', 'extremely', 'important', 'data', 'analytics', 'problems.', 'From', \"study's\", 'findings,', '\"truth', 'Big', 'Data\"', 'fundamentally', 'new', 'DQ', 'issue', 'Big', 'Data', 'analytics', 'projects.', 'Some', 'DQ', 'issue', 'exhibit', 'return-s-to-scale', 'effects,', 'become', 'less', 'pronounce', 'Big', 'Data', 'analytics,', 'though.', 'Big', 'Data', 'Quality', 'varies', 'one', 'type', 'Big', 'Data', 'another', 'one', 'Big', 'Data', 'technology', 'another.']\n",
      "abstract\\a73.txt\n",
      "\n",
      "['With', 'advent', 'Big', 'Data', 'technologies,', 'organization', 'efficiently', 'store', 'analyze', 'data', 'ever', 'before.', 'However,', 'extract', 'maximal', 'value', 'data', 'challenge', 'many', 'reasons.', 'For', 'example,', 'datasets', 'often', 'store', 'use', 'human-understandable', 'terms,', 'make', 'difficult', 'large', 'set', 'user', 'benefit', 'them.', 'Further,', 'give', 'different', 'type', 'data', 'may', 'best', 'store', 'use', 'different', 'technologies,', 'datasets', 'closely', 'related', 'may', 'store', 'separately', 'explicit', 'linkage.', 'Finally,', 'even', 'within', 'individual', 'data', 'stores,', 'often', 'inconsistency', 'data', 'representations,', 'whether', 'introduce', 'time', 'due', 'different', 'data', 'producers.', 'These', 'challenge', 'compound', 'frequent', 'addition', 'data,', 'include', 'new', 'raw', 'data', 'well', 'result', 'produce', 'large-scale', 'analytics.', 'Thus,', 'even', 'within', 'single', 'Big', 'Data', 'environment,', 'often', 'case', 'multiple', 'rich', 'datasets', 'exist', 'without', 'mean', 'access', 'unified', 'cohesive', 'way,', 'often', 'lead', 'lose', 'value.', 'This', 'paper', 'describes', 'development', 'Big', 'Data', 'management', 'infrastructure', 'semantic', 'technology', 'core', 'provide', 'unified', 'data', 'access', 'layer', 'consistent', 'approach', 'analytic', 'execution.', 'Semantic', 'technology', 'use', 'create', 'domain', 'model', 'describe', 'mutually', 'relevant', 'datasets', 'relationship', 'them,', 'graphical', 'user', 'interface', 'transparently', 'query', 'across', 'datasets', 'use', 'domain-model', 'terms.', 'This', 'prototype', 'system', 'built', 'GE', 'Power', \"Water's\", 'Power', 'Generation', 'Products', 'Engineering', 'Division,', 'produce', '50TB', 'gas', 'turbine', 'component', 'prototype', 'test', 'data', 'date.', 'The', 'system', 'expect', 'result', 'significant', 'saving', 'productivity', 'expenditure.']\n",
      "abstract\\a74.txt\n",
      "\n",
      "['The', 'propose', 'paper', 'present', 'novel', 'scheme', 'perform', 'precise', 'extraction', 'knowledge', 'complex', 'massive', 'stream', 'live', 'data', 'scene', 'crowd', 'place.', 'The', 'prime', 'contribution', 'propose', 'system', 'perform', 'enough', 'processing', 'raw', 'unstructured', 'distribute', 'data', 'multiple', 'location', 'processing', 'distribute', 'storage', 'mining', 'do', 'lesser', 'processing', 'time', 'high', 'degree', 'accuracy.', 'An', 'experimental', 'research', 'methodology', 'adopt', 'capture', 'signal', 'use', 'Logitech', 'HD', 'C920', 'process', 'Intel', 'Xeon', 'E5540', 'processor', '2', 'GPbs', 'connectivity.', 'The', 'raw', 'data', 'subject', 'pre-processing,', 'segmentation,', 'scene', 'profiling,', 'order', 'get', 'convolve', 'data', 'store', 'distributive', 'manner', 'use', 'Hadoop', 'mine', 'use', 'MapReduce.', 'The', 'comparative', 'study', 'outcome', 'show', 'lesser', 'processing', 'time', 'high', 'accuracy', 'compare', 'exist', 'relevant', 'analytics.']\n",
      "abstract\\a75.txt\n",
      "\n",
      "['The', 'enormous', 'volume', 'data', 'create', 'maintain', 'industries,', 'research', 'institution', 'verge', 'outgrow', 'infrastructure.', 'The', 'advancement', \"organization's\", 'work', 'flow', 'include', 'data', 'storage,', 'data', 'management,', 'data', 'maintenance,', 'data', 'integration,', 'data', 'interoperability.', 'Among', 'levels,', 'data', 'integration', 'data', 'interoperability', 'two', 'major', 'focus', 'area', 'organization', 'tend', 'implement', 'advancement', 'workflow.', 'Overall,', 'data', 'integration', 'data', 'interoperability', 'influence', \"organization's\", 'performance.', 'The', 'data', 'integration', 'data', 'interoperability', 'complex', 'challenge', 'organization', 'deploy', 'big', 'data', 'architecture', 'due', 'heterogeneous', 'nature', 'data', 'use', 'them.', 'Therefore,', 'require', 'comprehensive', 'approach', 'negotiate', 'challenge', 'integration', 'interoperability.', 'This', 'paper', 'focus', 'challenge', 'data', 'integration', 'data', 'interoperability', 'big', 'data.']\n",
      "abstract\\a76.txt\n",
      "\n",
      "['Data', 'sharing,', 'hot', 'issue', 'scholarly', 'communication,', 'regard', 'generate', 'big', 'data', 'little', 'data', 'little', 'science.', 'In', 'article,', 'conceptual', 'framework', 'research', 'support', 'platform', 'university', 'proposed,', 'survey', 'two', 'case', 'representative', 'subject-based', 'data', 'archive', 'Japan;', 'Data', 'Integration', 'Analysis', 'System', 'Program', '(DIAS)', 'Inter-university', 'Upper', 'atmosphere', 'Global', 'Observation', 'Network', '(IUGONET).']\n",
      "abstract\\a77.txt\n",
      "\n",
      "['Advancement', 'field', 'compute', 'remote', 'handheld', 'device', 'make', 'process', 'collect', 'geospatial', 'data', 'easy.', 'Most', 'time', 'researcher', 'scientist', 'easy', 'access', 'data', 'well.', 'However,', 'process', 'extract', 'processing', 'large', 'volume', 'data', 'several', 'source', 'time', 'consume', 'difficult.', 'In', 'case', 'scientist', 'rely', 'expensive', 'proprietary', 'software', '[1].', 'This', 'paper', 'discus', 'Computational', 'Scientists', 'Oak', 'Ridge', 'National', 'Laboratory', 'extracting,', 'normalizing,', 'processing', 'million', 'geospatial', 'data', 'point', 'multiple', 'data', 'source', 'integrate', 'common', 'data', 'format', 'help', 'user', 'find', 'access', 'data', 'use', 'flexible', 'visualization-based', 'user', 'interface.']\n",
      "abstract\\a78.txt\n",
      "\n",
      "['According', 'problem', 'efficient', 'datasets', 'cannot', 'quickly', 'obtain', 'social', 'medium', 'big', 'data', 'social', 'network', 'process', 'focus', 'mining', 'analysis.', 'An', 'effective', 'selection', 'method', 'cluster', 'mining', 'spacetime', 'large', 'data', 'proposed.', 'The', 'effective', 'selection', 'method', 'cluster', 'mining', 'divide', 'spatiotemporal', 'large', 'data', 'dimension', 'space,', 'time', 'attribute.', 'Then', 'exploratory', 'spatial', 'data', 'analysis(ESDA)', 'obtain', 'subset', 'get', 'datasets', 'potential', 'cluster', 'mining', 'quickly.', 'propose', 'method', 'verify', 'use', 'Weibo', 'check-in', 'data', 'Wuhan', '2011', '2015', 'mine', 'commercial', 'hotspots.', 'The', 'experimental', 'result', 'show', 'method', 'quickly', 'effectively', 'excavate', 'datasets', 'Weibo', 'check-in', 'data', 'reflect', 'distribution', 'Wuhan', 'business', 'circle,', 'excavate', 'datasets', 'characteristic', 'high', 'clustering,', 'small', 'volume,', 'high', 'precision.', 'The', 'effective', 'selection', 'method', 'cluster', 'mining', 'spatiotemporal', 'data', 'provide', 'fast', 'effective', 'method', 'idea', 'process', 'crowd', 'source', 'geographic', 'data', 'today.']\n",
      "abstract\\a79.txt\n",
      "\n",
      "['With', 'advent', 'big', 'data,', 'data', 'generated,', 'collected,', 'transformed,', 'process', 'analyze', 'unprecedented', 'scale.', 'Since', 'data', 'create', 'fast', 'velocity', 'large', 'variety,', 'quality', 'big', 'data', 'far', 'perfect.', 'Recent', 'study', 'show', 'poor', 'quality', 'bring', 'serious', 'erroneous', 'data', 'cost', 'result', 'big', 'data', 'analysis.', 'Data', 'validation', 'important', 'process', 'recognize', 'improve', 'data', 'quality.', 'In', 'paper,', 'case', 'study', 'relevant', 'big', 'data', 'quality', 'design', 'study', 'original', 'big', 'data', 'quality,', 'data', 'quality', 'dimension,', 'data', 'validation', 'process', 'tools.']\n",
      "abstract\\a8.txt\n",
      "\n",
      "['A', 'new', 'method', 'early', 'fault', 'diagnosis', 'manufacturing', 'system', 'base', 'machine', 'learn', 'presented.', 'It', 'necessary', 'manufacturing', 'enterprise', 'detect', 'state', 'production', 'process', 'real', 'time,', 'order', 'find', 'early', 'fault', 'machines,', 'loss', 'production', 'failure', 'investment', 'facility', 'maintenance', 'minimized.', 'This', 'paper', 'proposes', 'new', 'fault', 'diagnosis', 'model,', 'extract', 'multi-dimension', 'feature', 'detect', 'signal', 'supervise', 'different', 'feature', 'signal', 'simultaneously.', 'Based', 'model,', 'method', 'inductive', 'learn', 'adopt', 'obtain', 'statistical', 'boundary', 'vector', 'signal', 'automatically,', 'normal', 'feature', 'space', 'built,', 'accord', 'abnormal', 'signal', 'detected,', 'consequently', 'fault', 'complicate', 'system', 'found', 'easily.', 'Furthermore,', 'condition', 'without', 'exist', 'fault', 'samples,', 'precise', 'result', 'fault', 'diagnosis', 'also', 'achieve', 'real', 'time.', 'The', 'theoretical', 'analysis', 'simulation', 'example', 'demonstrate', 'effectiveness', 'method.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a80.txt\n",
      "\n",
      "['The', 'Atmospheric', 'Radiation', 'Measurement', '(ARM)', 'Climate', 'Research', 'Facility', '(www.arm.gov)', 'provide', 'atmospheric', 'observation', 'diverse', 'climatic', 'regime', 'around', 'world.', 'Currently,', 'ARM', 'archive', '22', 'million', 'user', 'assessable', 'data', 'files,', 'primarily', 'store', 'NetCDF', 'file', 'format,', 'total', 'data', 'volume', 'close', 'one', 'Petabyte.', 'In', 'paper,', 'discus', 'ARM', 'currently', 'storing,', 'distributing,', 'catalog', 'visualize', 'large', 'volume', 'multi-dimensional', 'climate', 'observation', 'model', 'data', 'also', 'describe', 'future', 'plan.']\n",
      "abstract\\a81.txt\n",
      "\n",
      "['The', 'advent', 'social', 'network', 'Internet-of-Things', 'result', 'unprecedented', 'capability', 'collecting,', 'share', 'analyze', 'massive', 'amount', 'data.', 'From', 'security', 'perspective,', 'Big', 'Data', 'may', 'seriously', 'weaken', 'confidentiality,', 'technique', 'improve', 'Big', 'Data', 'analytics', 'performance-including', 'early', 'fusion', 'heterogeneous', 'data', 'source', 'increase', 'hidden', 'redundancy', 'data', 'representation,', 'generate', 'ill-protected', 'copies.', 'This', 'gray', 'area', 'redundancy', 'trigger', 'new', 'disclosure', 'threat', 'challenge', 'traditional', 'technique', 'protect', 'privacy', 'confidentiality.', 'This', 'position', 'paper', 'start', 'propose', 'definition', 'Big', 'Data', 'Leak', 'threat', '(as', 'oppose', 'one', 'data', 'breach)', 'role', 'component', 'disclosure', 'risk.', 'Then,', 'discus', 'paradigm', 'Known,', 'Detect,', 'Contain', 'Recover', 'could', 'use', 'establish', 'Big', 'Data', 'security', 'practice', 'contain', 'disclosure', 'risk', 'connect', 'Big', 'Data', 'analytics.']\n",
      "abstract\\a82.txt\n",
      "\n",
      "['This', 'paper', 'test', 'whether', 'accurate', 'sale', 'forecast', 'Nike', 'possible', 'Facebook', 'data', 'event', 'related', 'Nike', 'affect', 'activity', \"Nike's\", 'Facebook', 'pages.', 'The', 'paper', 'draw', 'AIDA', 'sale', 'framework', '(Awareness,', 'Interest,', 'Desire,', 'Action)', 'domain', 'marketing', 'employ', 'method', 'social', 'set', 'analysis', 'domain', 'computational', 'social', 'science', 'model', 'sale', 'Big', 'Social', 'Data.', 'The', 'dataset', 'consists', '(a)', 'selection', \"Nike's\", 'Facebook', 'page', 'number', 'likes,', 'comments,', 'post', 'etc.', 'register', 'page', 'per', 'day', '(b)', 'business', 'data', 'term', 'quarterly', 'global', 'sale', 'figure', 'publish', \"Nike's\", 'financial', 'reports.', 'An', 'event', 'study', 'also', 'conduct', 'use', 'Social', 'Set', 'Visualizer', '(SoSeVi).', 'The', 'finding', 'suggest', 'Facebook', 'data', 'informational', 'value.', 'Some', 'simple', 'regression', 'model', 'high', 'forecasting', 'accuracy.', 'The', 'multiple', 'regression', 'low', 'forecasting', 'accuracy', 'cause', 'analysis', 'barrier', 'due', 'data', 'set', 'characteristic', 'perfect', 'multicollinearity.', 'The', 'event', 'study', 'found', 'abnormal', 'activity', 'around', 'several', 'Nike', 'specific', 'event', 'inference', 'activity', 'spikes,', 'whether', 'purely', 'event-related', 'coincidences,', 'determine', 'detailed', 'case-by-case', 'text', 'analysis.', 'Our', 'finding', 'help', 'ass', 'informational', 'value', 'Big', 'Social', 'Data', \"company's\", 'marketing', 'strategy,', 'sale', 'operation', 'supply', 'chain.']\n",
      "abstract\\a83.txt\n",
      "\n",
      "['Many', 'exist', 'data', 'mining', 'algorithm', 'search', 'interest', 'pattern', 'transactional', 'database', 'precise', 'data.', 'However,', 'situation', 'data', 'uncertain.', 'Items', 'transaction', 'probabilistic', 'database', 'uncertain', 'data', 'usually', 'associate', 'existential', 'probabilities,', 'express', 'likelihood', 'item', 'present', 'transaction.', 'When', 'compare', 'mining', 'precise', 'data,', 'search', 'space', 'mining', 'uncertain', 'data', 'much', 'large', 'due', 'presence', 'existential', 'probabilities.', 'This', 'problem', 'worsen', 'move', 'era', 'Big', 'data.', 'Furthermore,', 'many', 'real-life', 'applications,', 'user', 'may', 'interested', 'tiny', 'portion', 'large', 'search', 'space', 'Big', 'data', 'mining.', 'Without', 'provide', 'opportunity', 'user', 'express', 'interest', 'pattern', 'mined,', 'many', 'exist', 'data', 'mining', 'algorithm', 'return', 'numerous', 'pattern', '--', 'interesting.', 'In', 'paper,', 'propose', 'algorithm', '(i)', 'allows', 'user', 'express', 'interest', 'term', 'constraint', '(ii)', 'us', 'MapReduce', 'model', 'mine', 'uncertain', 'Big', 'data', 'frequent', 'pattern', 'satisfy', 'user-specified', 'constraints.', 'By', 'exploit', 'property', 'constraints,', 'algorithm', 'greatly', 'reduces', 'search', 'space', 'Big', 'data', 'mining', 'uncertain', 'data,', 'return', 'pattern', 'interest', 'user', 'Big', 'data', 'analytics.']\n",
      "abstract\\a84.txt\n",
      "\n",
      "['The', 'primary', 'objective', 'paper', 'present', 'detailed', 'analysis', 'various', 'platform', 'suitable', 'Big', 'Data', 'processing.', 'In', 'paper,', 'various', 'software', 'framework', 'available', 'Big', 'Data', 'analytics', 'survey', 'in-detail', 'assessment', 'strength', 'weakness', 'discussed.', 'In', 'addition', 'this,', 'widely', 'use', 'data', 'mining', 'algorithm', 'discuss', 'adaptation', 'Big', 'Data', 'analysis', 'w.r.t', 'suitability', 'handle', 'real-world', 'application', 'problems.', 'Future', 'trend', 'Big', 'Data', 'processing', 'analytics', 'predict', 'effective', 'implementation', 'well', 'establish', 'widely', 'use', 'data', 'mining', 'algorithm', 'consider', 'strength', 'software', 'framework', 'platform', 'available.', 'Hybrid', 'approach', '(integration', 'two', 'platforms)', 'may', 'appropriate', 'specific', 'data', 'mining', 'algorithm', 'highly', 'adaptable', 'well', 'perform', 'real-time', 'processing.']\n",
      "abstract\\a85.txt\n",
      "\n",
      "['In', 'area', 'big', 'data,', 'people', 'new', 'perspective', 'counter-terrorism', 'research.', 'In', 'paper,', 'carry', 'systematic', 'research', 'application', 'big', 'data', 'counter-terrorism', 'field', 'use', 'quantitative', 'analysis', 'method.', 'And', 'demonstrate', 'effect', 'big', 'data', 'counter-terrorism', 'research', 'data', 'collection', 'preprocessing,', 'data', 'mining', 'analysis,', 'monitoring', 'warn', 'three', 'aspects.', 'After', 'that,', 'use', 'data', 'The', 'Times', 'The', 'New', 'York', 'Times', 'WUC', '2012', 'analysis', 'argument.', 'Finally,', 'concludes', 'deficiency', 'research', 'territory', 'counter-terrorism', 'use', 'big', 'data', 'problem', 'worth', 'study', 'future.']\n",
      "abstract\\a86.txt\n",
      "\n",
      "['Large', 'amount', 'data', 'generate', 'every', 'day', 'create', 'new', 'challenge', 'opportunity', 'lead', 'extraordinary', 'new', 'knowledge', 'discovery', 'many', 'application', 'domain', 'range', 'science', 'engineering', 'business.', 'One', 'main', 'challenge', 'era', 'Big', 'Data', 'efficiently', 'manage', 'analyse', 'scale', 'data.', 'This', 'challenge', 'due', 'size', 'data,', 'also', 'due', 'heterogeneous', 'nature', 'geographic', 'location.', 'In', 'sense,', 'cloud', 'become', 'increasingly', 'popular', 'infrastructure', 'enable', 'large-scale', 'data', 'intensive', 'scientific', 'business', 'applications.', 'Cloud', 'provide', 'suitable', 'environment', 'processing', 'Big', 'Data', 'application', 'process', 'large', 'volume', 'data', 'parallel', 'processing', 'data.', 'Due', 'geographical', 'distribution', 'data', 'different', 'variety', 'data', 'advantage', 'use', 'federate', 'Inter-Cloud', 'environment', 'move', 'large', 'volume', 'data', 'avoided.', 'Workflows', 'use', 'allocate', 'schedule', 'execution', 'Big', 'Data', 'application', 'optimize', 'manner.', 'In', 'paper', 'present', 'need', 'execution', 'Big', 'Data', 'Application', 'workflow', 'Cloud', 'Inter-Cloud', 'environments.']\n",
      "abstract\\a87.txt\n",
      "\n",
      "['Artificial', 'intelligence,', 'particularly', 'machine', 'learning,', 'use', 'many', 'way', 'research', 'community', 'turn', 'variety', 'diverse', 'even', 'heterogeneous', 'data', 'source', 'high', 'quality', 'fact', 'knowledge,', 'provide', 'premier', 'capability', 'accurate', 'pattern', 'discovery.', 'However,', 'apply', 'machine', 'learn', 'strategy', 'big', 'complex', 'datasets', 'computationally', 'expensive,', 'consumes', 'large', 'amount', 'logical', 'physical', 'resources,', 'data', 'file', 'space,', 'CPU,', 'memory.', 'A', 'sophisticated', 'platform', 'efficient', 'big', 'data', 'analytics', 'become', 'important', 'day', 'data', 'amount', 'generate', 'daily', 'basis', 'exceeds', 'quintillion', 'bytes.', 'Apache', 'Spark', 'MLlib', 'one', 'prominent', 'platform', 'big', 'data', 'analysis', 'offer', 'set', 'excellent', 'functionality', 'different', 'machine', 'learn', 'task', 'range', 'regression,', 'classification,', 'dimension', 'reduction', 'cluster', 'rule', 'extraction.', 'In', 'contribution,', 'explore,', 'computational', 'perspective,', 'expand', 'body', 'Apache', 'Spark', 'MLlib', '2.0', 'open-source,', 'distributed,', 'scalable,', 'platform', 'independent', 'machine', 'learn', 'library.', 'Specifically,', 'perform', 'several', 'real', 'world', 'machine', 'learn', 'experiment', 'examine', 'qualitative', 'quantitative', 'attribute', 'platform.', 'Furthermore,', 'highlight', 'current', 'trend', 'big', 'data', 'machine', 'learn', 'research', 'provide', 'insight', 'future', 'work.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract\\a88.txt\n",
      "\n",
      "['Big', 'Data', 'contains', 'massive', 'information,', 'generate', 'heterogeneous,', 'autonomous', 'source', 'distribute', 'anonymous', 'platforms.', 'Since,', 'raise', 'extreme', 'challenge', 'organization', 'store', 'process', 'data.', 'Conventional', 'pathway', 'store', 'process', 'happen', 'collection', 'manual', 'step', 'consume', 'various', 'resources.', 'An', 'automate', 'real-time', 'online', 'analytical', 'process', 'cognitive', 'solution.', 'Therefore', 'need', 'state', 'art', 'approach', 'overcome', 'barrier', 'concern', 'currently', 'face', 'Big', 'Data', 'industry.', 'In', 'paper', 'propose', 'novel', 'architecture', 'automate', 'data', 'analytics', 'process', 'use', 'Nested', 'Automatic', 'Service', 'Composition', '(NASC)', 'CRoss', 'Industry', 'Standard', 'Platform', 'Data', 'Mining', '(CRISP-DM)', 'main', 'base', 'technology', 'solution.', 'NASC', 'well', 'define', 'scalable', 'technology', 'automate', 'multi-disciplined', 'problem', 'domains.', 'Since', 'CRISP-DM', 'also', 'well-known', 'data', 'science', 'process', 'use', 'innovative', 'accumulator', 'multi-dimensional', 'data', 'sets.', 'CRISP-DM', 'mapped', 'Big', 'Data', 'analytical', 'process', 'NASC', 'automate', 'CRISP-DM', 'process', 'intelligent', 'innovative', 'way.']\n",
      "abstract\\a9.txt\n",
      "\n",
      "['The', 'support', 'vector', 'machine', 'new', 'statistical', 'learn', 'algorithm', 'developed', 'recent', 'years.', 'They', 'advantage', 'many', 'region', 'like', 'pattern', 'recognition.', 'The', 'kernel', 'function', 'important', 'classification', 'ability.', 'This', 'paper', 'present', 'crossbreed', 'genetic', 'algorithm', 'base', 'method', 'choose', 'kernel', 'function', 'parameters.', 'The', 'crossbreed', 'genetic', 'algorithm', 'us', 'two', 'fitness', 'function', 'produce', 'accord', 'two', 'criterion', \"SVM's\", 'performance.', 'The', 'experiment', 'prove', 'algorithm', 'find', 'effectively', 'optimal', 'kernel', 'function', 'parameters,', 'helpful', 'increase', 'support', 'vector', \"machines'\", 'performance', 'fact.']\n"
     ]
    }
   ],
   "source": [
    "words_dir = 'abstract'\n",
    "tags_directory = 'tags'\n",
    "Words, all_words, all_words_heading = read_words(words_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "4147\n"
     ]
    }
   ],
   "source": [
    "cou, Tags = read_tags(tags_directory)\n",
    "#df = pd.DataFrame(Tags)\n",
    "Words = np.array(Words)\n",
    "# exploring frequency of all words not in heading\n",
    "import nltk\n",
    "freq = nltk.FreqDist(all_words + all_words_heading)\n",
    "common = freq.most_common(3000)\n",
    "common = list(common)\n",
    "\n",
    "features = []\n",
    "features += [w[0] for w in common]\n",
    "features += [w for w in all_words_heading if w not in common]\n",
    "print(len(common))\n",
    "print(len(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geographic location</th>\n",
       "      <th>ï»¿Intelligent networks</th>\n",
       "      <th>Life estimation</th>\n",
       "      <th>Cloud computing</th>\n",
       "      <th>fault samples</th>\n",
       "      <th>recognition rate</th>\n",
       "      <th>DQN</th>\n",
       "      <th>doubles pong game</th>\n",
       "      <th>Predictive medicine</th>\n",
       "      <th>Customer relationship management</th>\n",
       "      <th>...</th>\n",
       "      <th>weighting function</th>\n",
       "      <th>Companies</th>\n",
       "      <th>HDDs</th>\n",
       "      <th>dynamic backward error assignment</th>\n",
       "      <th>GPU processing power</th>\n",
       "      <th>Concrete</th>\n",
       "      <th>Error analysis</th>\n",
       "      <th>large-scaled neural systems</th>\n",
       "      <th>social set visualizer</th>\n",
       "      <th>hybrid multilayer feedforward neural network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 1774 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     geographic location  ï»¿Intelligent networks   Life estimation   \\\n",
       "0                      0                        0                  0   \n",
       "1                      0                        0                  0   \n",
       "2                      0                        0                  1   \n",
       "3                      0                        0                  0   \n",
       "4                      0                        0                  0   \n",
       "5                      0                        0                  0   \n",
       "6                      0                        0                  0   \n",
       "7                      0                        0                  0   \n",
       "8                      0                        0                  0   \n",
       "9                      0                        0                  0   \n",
       "10                     0                        0                  0   \n",
       "11                     0                        0                  0   \n",
       "12                     0                        0                  0   \n",
       "13                     0                        0                  0   \n",
       "14                     0                        0                  0   \n",
       "15                     0                        0                  0   \n",
       "16                     0                        0                  0   \n",
       "17                     0                        0                  0   \n",
       "18                     0                        0                  0   \n",
       "19                     0                        0                  0   \n",
       "20                     0                        0                  0   \n",
       "21                     0                        0                  0   \n",
       "22                     0                        0                  0   \n",
       "23                     0                        0                  0   \n",
       "24                     0                        0                  0   \n",
       "25                     0                        0                  0   \n",
       "26                     0                        0                  0   \n",
       "27                     0                        0                  0   \n",
       "28                     0                        0                  0   \n",
       "29                     0                        0                  0   \n",
       "..                   ...                      ...                ...   \n",
       "106                    0                        0                  0   \n",
       "107                    0                        0                  0   \n",
       "108                    0                        0                  0   \n",
       "109                    0                        0                  0   \n",
       "110                    0                        0                  0   \n",
       "111                    0                        0                  0   \n",
       "112                    0                        0                  0   \n",
       "113                    0                        0                  0   \n",
       "114                    0                        0                  0   \n",
       "115                    0                        0                  0   \n",
       "116                    0                        0                  0   \n",
       "117                    0                        0                  0   \n",
       "118                    0                        0                  0   \n",
       "119                    0                        0                  0   \n",
       "120                    0                        0                  0   \n",
       "121                    0                        0                  0   \n",
       "122                    0                        0                  0   \n",
       "123                    0                        0                  0   \n",
       "124                    0                        0                  0   \n",
       "125                    0                        0                  0   \n",
       "126                    0                        0                  0   \n",
       "127                    0                        0                  0   \n",
       "128                    0                        0                  0   \n",
       "129                    0                        0                  0   \n",
       "130                    0                        0                  0   \n",
       "131                    0                        0                  0   \n",
       "132                    1                        0                  0   \n",
       "133                    0                        0                  0   \n",
       "134                    0                        0                  0   \n",
       "135                    0                        0                  0   \n",
       "\n",
       "     Cloud computing  fault samples  recognition rate\\n  DQN  \\\n",
       "0                  0              0                   0    0   \n",
       "1                  0              0                   0    0   \n",
       "2                  0              0                   0    0   \n",
       "3                  0              0                   0    0   \n",
       "4                  0              0                   0    0   \n",
       "5                  0              0                   0    0   \n",
       "6                  0              0                   0    0   \n",
       "7                  0              0                   0    0   \n",
       "8                  0              0                   0    0   \n",
       "9                  0              0                   0    0   \n",
       "10                 0              0                   0    0   \n",
       "11                 0              0                   0    0   \n",
       "12                 0              0                   0    0   \n",
       "13                 0              0                   0    0   \n",
       "14                 0              0                   0    0   \n",
       "15                 0              0                   0    0   \n",
       "16                 0              0                   0    0   \n",
       "17                 0              0                   0    0   \n",
       "18                 0              0                   0    0   \n",
       "19                 0              0                   0    0   \n",
       "20                 0              0                   0    0   \n",
       "21                 0              0                   0    0   \n",
       "22                 0              0                   0    0   \n",
       "23                 0              0                   0    0   \n",
       "24                 0              0                   0    0   \n",
       "25                 0              0                   0    0   \n",
       "26                 0              0                   0    0   \n",
       "27                 0              0                   0    0   \n",
       "28                 0              0                   0    0   \n",
       "29                 0              0                   0    0   \n",
       "..               ...            ...                 ...  ...   \n",
       "106                0              0                   0    0   \n",
       "107                0              0                   0    0   \n",
       "108                0              0                   0    0   \n",
       "109                0              0                   0    0   \n",
       "110                0              0                   0    0   \n",
       "111                0              0                   0    0   \n",
       "112                0              0                   0    0   \n",
       "113                0              0                   0    0   \n",
       "114                0              0                   0    0   \n",
       "115                0              0                   0    0   \n",
       "116                0              0                   0    0   \n",
       "117                0              0                   0    0   \n",
       "118                0              0                   0    0   \n",
       "119                1              0                   0    0   \n",
       "120                0              0                   0    0   \n",
       "121                0              0                   0    0   \n",
       "122                0              0                   0    0   \n",
       "123                0              0                   0    0   \n",
       "124                0              0                   0    0   \n",
       "125                0              1                   0    0   \n",
       "126                0              0                   0    0   \n",
       "127                0              0                   0    0   \n",
       "128                0              0                   0    0   \n",
       "129                0              0                   0    0   \n",
       "130                1              0                   0    0   \n",
       "131                0              0                   0    0   \n",
       "132                0              0                   0    0   \n",
       "133                0              0                   0    0   \n",
       "134                0              0                   0    0   \n",
       "135                0              0                   0    0   \n",
       "\n",
       "     doubles pong game  Predictive medicine  \\\n",
       "0                    0                    0   \n",
       "1                    0                    0   \n",
       "2                    0                    0   \n",
       "3                    0                    0   \n",
       "4                    0                    0   \n",
       "5                    0                    0   \n",
       "6                    0                    0   \n",
       "7                    0                    0   \n",
       "8                    0                    0   \n",
       "9                    0                    0   \n",
       "10                   0                    0   \n",
       "11                   0                    0   \n",
       "12                   0                    0   \n",
       "13                   0                    0   \n",
       "14                   0                    0   \n",
       "15                   0                    0   \n",
       "16                   0                    0   \n",
       "17                   0                    0   \n",
       "18                   0                    0   \n",
       "19                   0                    0   \n",
       "20                   0                    0   \n",
       "21                   0                    0   \n",
       "22                   0                    0   \n",
       "23                   0                    0   \n",
       "24                   0                    0   \n",
       "25                   0                    0   \n",
       "26                   0                    0   \n",
       "27                   0                    0   \n",
       "28                   0                    0   \n",
       "29                   0                    0   \n",
       "..                 ...                  ...   \n",
       "106                  0                    0   \n",
       "107                  0                    0   \n",
       "108                  0                    0   \n",
       "109                  0                    0   \n",
       "110                  0                    0   \n",
       "111                  0                    0   \n",
       "112                  0                    0   \n",
       "113                  0                    1   \n",
       "114                  0                    0   \n",
       "115                  0                    0   \n",
       "116                  0                    0   \n",
       "117                  0                    0   \n",
       "118                  0                    0   \n",
       "119                  0                    0   \n",
       "120                  0                    0   \n",
       "121                  0                    0   \n",
       "122                  0                    0   \n",
       "123                  0                    0   \n",
       "124                  0                    0   \n",
       "125                  0                    0   \n",
       "126                  0                    0   \n",
       "127                  0                    0   \n",
       "128                  0                    0   \n",
       "129                  0                    0   \n",
       "130                  0                    0   \n",
       "131                  0                    0   \n",
       "132                  0                    0   \n",
       "133                  0                    0   \n",
       "134                  0                    0   \n",
       "135                  0                    0   \n",
       "\n",
       "      Customer relationship management   \\\n",
       "0                                     0   \n",
       "1                                     0   \n",
       "2                                     0   \n",
       "3                                     0   \n",
       "4                                     0   \n",
       "5                                     0   \n",
       "6                                     0   \n",
       "7                                     0   \n",
       "8                                     0   \n",
       "9                                     0   \n",
       "10                                    0   \n",
       "11                                    0   \n",
       "12                                    0   \n",
       "13                                    0   \n",
       "14                                    0   \n",
       "15                                    0   \n",
       "16                                    0   \n",
       "17                                    0   \n",
       "18                                    0   \n",
       "19                                    0   \n",
       "20                                    0   \n",
       "21                                    0   \n",
       "22                                    0   \n",
       "23                                    0   \n",
       "24                                    0   \n",
       "25                                    0   \n",
       "26                                    0   \n",
       "27                                    0   \n",
       "28                                    0   \n",
       "29                                    0   \n",
       "..                                  ...   \n",
       "106                                   0   \n",
       "107                                   0   \n",
       "108                                   0   \n",
       "109                                   0   \n",
       "110                                   0   \n",
       "111                                   0   \n",
       "112                                   0   \n",
       "113                                   0   \n",
       "114                                   0   \n",
       "115                                   0   \n",
       "116                                   0   \n",
       "117                                   0   \n",
       "118                                   0   \n",
       "119                                   0   \n",
       "120                                   0   \n",
       "121                                   0   \n",
       "122                                   0   \n",
       "123                                   0   \n",
       "124                                   0   \n",
       "125                                   0   \n",
       "126                                   0   \n",
       "127                                   0   \n",
       "128                                   0   \n",
       "129                                   0   \n",
       "130                                   0   \n",
       "131                                   0   \n",
       "132                                   0   \n",
       "133                                   0   \n",
       "134                                   0   \n",
       "135                                   0   \n",
       "\n",
       "                         ...                       weighting function  \\\n",
       "0                        ...                                        0   \n",
       "1                        ...                                        0   \n",
       "2                        ...                                        0   \n",
       "3                        ...                                        0   \n",
       "4                        ...                                        0   \n",
       "5                        ...                                        0   \n",
       "6                        ...                                        0   \n",
       "7                        ...                                        0   \n",
       "8                        ...                                        0   \n",
       "9                        ...                                        0   \n",
       "10                       ...                                        0   \n",
       "11                       ...                                        0   \n",
       "12                       ...                                        0   \n",
       "13                       ...                                        0   \n",
       "14                       ...                                        0   \n",
       "15                       ...                                        0   \n",
       "16                       ...                                        0   \n",
       "17                       ...                                        0   \n",
       "18                       ...                                        0   \n",
       "19                       ...                                        0   \n",
       "20                       ...                                        0   \n",
       "21                       ...                                        0   \n",
       "22                       ...                                        0   \n",
       "23                       ...                                        0   \n",
       "24                       ...                                        0   \n",
       "25                       ...                                        0   \n",
       "26                       ...                                        0   \n",
       "27                       ...                                        0   \n",
       "28                       ...                                        0   \n",
       "29                       ...                                        0   \n",
       "..                       ...                                      ...   \n",
       "106                      ...                                        0   \n",
       "107                      ...                                        0   \n",
       "108                      ...                                        0   \n",
       "109                      ...                                        0   \n",
       "110                      ...                                        0   \n",
       "111                      ...                                        0   \n",
       "112                      ...                                        0   \n",
       "113                      ...                                        0   \n",
       "114                      ...                                        0   \n",
       "115                      ...                                        0   \n",
       "116                      ...                                        0   \n",
       "117                      ...                                        0   \n",
       "118                      ...                                        0   \n",
       "119                      ...                                        0   \n",
       "120                      ...                                        0   \n",
       "121                      ...                                        0   \n",
       "122                      ...                                        0   \n",
       "123                      ...                                        0   \n",
       "124                      ...                                        0   \n",
       "125                      ...                                        0   \n",
       "126                      ...                                        0   \n",
       "127                      ...                                        0   \n",
       "128                      ...                                        0   \n",
       "129                      ...                                        0   \n",
       "130                      ...                                        0   \n",
       "131                      ...                                        0   \n",
       "132                      ...                                        0   \n",
       "133                      ...                                        0   \n",
       "134                      ...                                        0   \n",
       "135                      ...                                        0   \n",
       "\n",
       "      Companies   HDDs  dynamic backward error assignment  \\\n",
       "0              0     0                                  0   \n",
       "1              0     0                                  0   \n",
       "2              0     0                                  0   \n",
       "3              0     0                                  0   \n",
       "4              0     0                                  0   \n",
       "5              0     0                                  0   \n",
       "6              0     0                                  0   \n",
       "7              0     0                                  0   \n",
       "8              0     0                                  0   \n",
       "9              0     0                                  0   \n",
       "10             0     0                                  0   \n",
       "11             0     0                                  0   \n",
       "12             0     0                                  0   \n",
       "13             0     0                                  0   \n",
       "14             0     0                                  0   \n",
       "15             0     0                                  0   \n",
       "16             0     0                                  0   \n",
       "17             0     0                                  0   \n",
       "18             0     0                                  0   \n",
       "19             0     0                                  0   \n",
       "20             0     0                                  0   \n",
       "21             0     0                                  0   \n",
       "22             0     0                                  0   \n",
       "23             0     0                                  0   \n",
       "24             0     0                                  0   \n",
       "25             0     0                                  0   \n",
       "26             0     0                                  0   \n",
       "27             0     0                                  0   \n",
       "28             0     0                                  0   \n",
       "29             1     0                                  0   \n",
       "..           ...   ...                                ...   \n",
       "106            0     0                                  0   \n",
       "107            0     0                                  0   \n",
       "108            0     0                                  0   \n",
       "109            0     0                                  0   \n",
       "110            0     0                                  0   \n",
       "111            0     0                                  0   \n",
       "112            0     0                                  0   \n",
       "113            0     0                                  0   \n",
       "114            0     0                                  0   \n",
       "115            0     0                                  0   \n",
       "116            0     0                                  0   \n",
       "117            0     0                                  0   \n",
       "118            0     0                                  0   \n",
       "119            0     0                                  0   \n",
       "120            0     0                                  0   \n",
       "121            0     0                                  0   \n",
       "122            0     0                                  0   \n",
       "123            0     0                                  0   \n",
       "124            0     0                                  0   \n",
       "125            0     0                                  0   \n",
       "126            0     0                                  0   \n",
       "127            0     0                                  0   \n",
       "128            0     0                                  0   \n",
       "129            0     0                                  0   \n",
       "130            0     0                                  0   \n",
       "131            0     0                                  0   \n",
       "132            0     0                                  0   \n",
       "133            0     0                                  0   \n",
       "134            0     0                                  0   \n",
       "135            0     0                                  0   \n",
       "\n",
       "     GPU processing power  Concrete   Error analysis   \\\n",
       "0                       0         0                 0   \n",
       "1                       0         0                 0   \n",
       "2                       0         0                 0   \n",
       "3                       0         0                 0   \n",
       "4                       0         0                 0   \n",
       "5                       0         0                 0   \n",
       "6                       0         0                 0   \n",
       "7                       0         0                 0   \n",
       "8                       0         0                 0   \n",
       "9                       0         0                 0   \n",
       "10                      0         0                 0   \n",
       "11                      0         0                 0   \n",
       "12                      0         0                 0   \n",
       "13                      0         0                 0   \n",
       "14                      0         0                 0   \n",
       "15                      0         0                 0   \n",
       "16                      0         0                 0   \n",
       "17                      0         0                 0   \n",
       "18                      0         0                 0   \n",
       "19                      0         0                 0   \n",
       "20                      0         0                 0   \n",
       "21                      0         0                 0   \n",
       "22                      0         0                 0   \n",
       "23                      0         0                 0   \n",
       "24                      0         0                 0   \n",
       "25                      0         0                 0   \n",
       "26                      0         0                 0   \n",
       "27                      0         0                 0   \n",
       "28                      0         0                 0   \n",
       "29                      0         0                 0   \n",
       "..                    ...       ...               ...   \n",
       "106                     0         0                 0   \n",
       "107                     0         0                 0   \n",
       "108                     0         0                 0   \n",
       "109                     0         0                 0   \n",
       "110                     0         0                 0   \n",
       "111                     0         1                 0   \n",
       "112                     0         0                 0   \n",
       "113                     0         0                 0   \n",
       "114                     0         0                 0   \n",
       "115                     0         0                 0   \n",
       "116                     0         0                 0   \n",
       "117                     0         0                 0   \n",
       "118                     0         0                 0   \n",
       "119                     0         0                 0   \n",
       "120                     0         0                 0   \n",
       "121                     0         0                 0   \n",
       "122                     0         0                 0   \n",
       "123                     0         0                 0   \n",
       "124                     0         0                 0   \n",
       "125                     0         0                 0   \n",
       "126                     0         0                 0   \n",
       "127                     0         0                 0   \n",
       "128                     0         0                 0   \n",
       "129                     0         0                 0   \n",
       "130                     0         0                 0   \n",
       "131                     0         0                 0   \n",
       "132                     0         0                 0   \n",
       "133                     0         0                 0   \n",
       "134                     0         0                 0   \n",
       "135                     0         0                 0   \n",
       "\n",
       "     large-scaled neural systems  social set visualizer  \\\n",
       "0                              0                      0   \n",
       "1                              0                      0   \n",
       "2                              0                      0   \n",
       "3                              0                      0   \n",
       "4                              0                      0   \n",
       "5                              0                      0   \n",
       "6                              0                      0   \n",
       "7                              0                      0   \n",
       "8                              0                      0   \n",
       "9                              0                      0   \n",
       "10                             0                      0   \n",
       "11                             0                      0   \n",
       "12                             0                      0   \n",
       "13                             0                      0   \n",
       "14                             0                      0   \n",
       "15                             0                      0   \n",
       "16                             0                      0   \n",
       "17                             0                      0   \n",
       "18                             0                      0   \n",
       "19                             0                      0   \n",
       "20                             0                      0   \n",
       "21                             0                      0   \n",
       "22                             0                      0   \n",
       "23                             0                      0   \n",
       "24                             0                      0   \n",
       "25                             0                      0   \n",
       "26                             0                      0   \n",
       "27                             0                      0   \n",
       "28                             0                      0   \n",
       "29                             0                      0   \n",
       "..                           ...                    ...   \n",
       "106                            0                      0   \n",
       "107                            0                      0   \n",
       "108                            0                      0   \n",
       "109                            0                      0   \n",
       "110                            0                      0   \n",
       "111                            0                      0   \n",
       "112                            0                      0   \n",
       "113                            0                      0   \n",
       "114                            0                      0   \n",
       "115                            0                      0   \n",
       "116                            0                      0   \n",
       "117                            0                      0   \n",
       "118                            0                      0   \n",
       "119                            0                      0   \n",
       "120                            0                      0   \n",
       "121                            0                      0   \n",
       "122                            0                      0   \n",
       "123                            0                      0   \n",
       "124                            0                      0   \n",
       "125                            0                      0   \n",
       "126                            0                      0   \n",
       "127                            0                      0   \n",
       "128                            0                      1   \n",
       "129                            0                      0   \n",
       "130                            0                      0   \n",
       "131                            0                      0   \n",
       "132                            0                      0   \n",
       "133                            0                      0   \n",
       "134                            0                      0   \n",
       "135                            0                      0   \n",
       "\n",
       "     hybrid multilayer feedforward neural network  \n",
       "0                                               0  \n",
       "1                                               0  \n",
       "2                                               0  \n",
       "3                                               0  \n",
       "4                                               0  \n",
       "5                                               0  \n",
       "6                                               0  \n",
       "7                                               0  \n",
       "8                                               0  \n",
       "9                                               0  \n",
       "10                                              0  \n",
       "11                                              0  \n",
       "12                                              0  \n",
       "13                                              0  \n",
       "14                                              0  \n",
       "15                                              0  \n",
       "16                                              0  \n",
       "17                                              0  \n",
       "18                                              0  \n",
       "19                                              0  \n",
       "20                                              0  \n",
       "21                                              0  \n",
       "22                                              0  \n",
       "23                                              0  \n",
       "24                                              0  \n",
       "25                                              0  \n",
       "26                                              0  \n",
       "27                                              0  \n",
       "28                                              0  \n",
       "29                                              0  \n",
       "..                                            ...  \n",
       "106                                             0  \n",
       "107                                             0  \n",
       "108                                             0  \n",
       "109                                             0  \n",
       "110                                             0  \n",
       "111                                             0  \n",
       "112                                             0  \n",
       "113                                             0  \n",
       "114                                             0  \n",
       "115                                             0  \n",
       "116                                             0  \n",
       "117                                             0  \n",
       "118                                             0  \n",
       "119                                             0  \n",
       "120                                             0  \n",
       "121                                             0  \n",
       "122                                             0  \n",
       "123                                             0  \n",
       "124                                             0  \n",
       "125                                             0  \n",
       "126                                             0  \n",
       "127                                             0  \n",
       "128                                             0  \n",
       "129                                             0  \n",
       "130                                             0  \n",
       "131                                             0  \n",
       "132                                             0  \n",
       "133                                             0  \n",
       "134                                             0  \n",
       "135                                             0  \n",
       "\n",
       "[136 rows x 1774 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 5. 0. ... 0. 0. 0.]\n",
      " [4. 7. 3. ... 0. 0. 0.]\n",
      " [6. 3. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [7. 5. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 4. ... 3. 3. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=GaussianNB(priors=None),\n",
       "        require_dense=[True, True])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "variable_code, ctr = read_files(words_dir, tags_directory)\n",
    "columns = list(Tags)\n",
    "rows = list(range(ctr))\n",
    "dataFrame = np.zeros((len(rows), len(columns)))\n",
    "#df = tag_updater(dataFrame, variable_code, columns)\n",
    "\n",
    "df = pd.DataFrame(data = dataFrame, index = rows, columns = columns, dtype='int64')\n",
    "# print(variable_code)\n",
    "Y = tag_updater(df, variable_code)\n",
    "#print(df.at[1, ' Machine learning '])\n",
    "# for x in df['Computers']:\n",
    "#     print(x)\n",
    "\n",
    "display(Y)\n",
    "Y.fillna(0, inplace=True)\n",
    "\n",
    "X = extract_features(Words, features)\n",
    "X_train = pd.DataFrame(data = X, index = rows, columns = features, dtype='int64')\n",
    "\n",
    "\n",
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "# train\n",
    "classifier.fit(X_train, Y)\n",
    "# predict\n",
    "#predictions = classifier.predict(X_train)\n",
    "#print(predictions.toarray())\n",
    "#print(accuracy_score(Y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "words_dir = 'testing_2'\n",
    "Words, waste1, waste2 = read_words(words_dir)\n",
    "X = extract_features(Words, features)\n",
    "rows = list(range(1))\n",
    "X_test = pd.DataFrame(data = X, columns = features, dtype='int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>learn</th>\n",
       "      <th>The</th>\n",
       "      <th>use</th>\n",
       "      <th>neural</th>\n",
       "      <th>big</th>\n",
       "      <th>machine</th>\n",
       "      <th>Data</th>\n",
       "      <th>deep</th>\n",
       "      <th>network</th>\n",
       "      <th>...</th>\n",
       "      <th>Composition</th>\n",
       "      <th>ï»¿A</th>\n",
       "      <th>method</th>\n",
       "      <th>choose</th>\n",
       "      <th>kernel</th>\n",
       "      <th>function</th>\n",
       "      <th>parameters</th>\n",
       "      <th>support</th>\n",
       "      <th>vector</th>\n",
       "      <th>machines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  learn  The  use  neural  big  machine  Data  deep  network    ...     \\\n",
       "0     0      0    0    0       0    0        0     0     0        0    ...      \n",
       "\n",
       "   Composition  ï»¿A  method  choose  kernel  function  parameters  support  \\\n",
       "0            0     0       0       0       0         0           0        0   \n",
       "\n",
       "   vector  machines  \n",
       "0       0         0  \n",
       "\n",
       "[1 rows x 4147 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_test)\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1774 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Column format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions\n",
    "display(predictions)\n",
    "predictions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "print(type(predictions))\n",
    "a = predictions.nonzero()\n",
    "#a.row[a.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(self):\n",
    "    A = self.tocoo()\n",
    "    nz_mask = A.data != 0\n",
    "    return (list(A.col[nz_mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((predictions.shape[0], len(columns)))\n",
    "dataFrame5 = np.zeros((predictions.shape[0], len(columns)))\n",
    "ct = 0\n",
    "for i in predictions:\n",
    "    b = find_index(i)\n",
    "    for j in b:\n",
    "        dataFrame5[ct,j] +=1\n",
    "    ct+=1\n",
    "print(dataFrame5)\n",
    "for i in dataFrame5:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dataFrame))\n",
    "\n",
    "converting = pd.DataFrame(data = dataFrame5, columns = columns, dtype='int64')\n",
    "display(converting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('file_predicted_skills.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_have = []\n",
    "print('------------------------TECHNICAL SKILLS REQUIRED-----------------------------')\n",
    "for i in b:\n",
    "    print(columns[i])\n",
    "    we_have.append(columns[i])\n",
    "    \n",
    "#we_have.append('artificial intelligence')\n",
    "#we_have.append('Machine learning algorithms')\n",
    "#we_have.append('Support vector machines')\n",
    "#we_have.append('Kernel')\n",
    "\n",
    "print(we_have)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is keyword extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next comes the wiki reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n",
    "def load_skill_set():\n",
    "\n",
    "    skill_dict = dict()\n",
    "    pick_file = open(\"final_skill_dict.pickle\", \"rb\")\n",
    "    skill_dict = pickle.load(pick_file)\n",
    "    pick_file.close()\n",
    "    return skill_dict\n",
    "\n",
    "\n",
    "skill_dict = load_skill_set()\n",
    "\n",
    "\n",
    "def get_skills(skill_dic,topic):\n",
    "\n",
    "    # print(\"getting skill set for \",topic)\n",
    "    skill_set = set()\n",
    "    for word in topic.split(' '):\n",
    "        # print(\"for word=\",word)\n",
    "        if word.strip().isalpha():\n",
    "            word = word.strip().lower()\n",
    "            wordnet_pos = get_wordnet_pos(nltk.pos_tag([word])[0][1])\n",
    "            if wordnet_pos == '':\n",
    "                word = lemmatizer.lemmatize(word)\n",
    "            else:\n",
    "                word = lemmatizer.lemmatize(word, wordnet_pos)\n",
    "\n",
    "            try:\n",
    "                curr_skill_set = skill_dic[word]\n",
    "                # print(\"skill set=\",curr_skill_set)\n",
    "                if len(skill_set) == 0:\n",
    "                    skill_set = curr_skill_set\n",
    "                else:\n",
    "                    skill_set = skill_set.intersection(curr_skill_set)\n",
    "\n",
    "                #print(\"intersection=\",skill_set)\n",
    "            except KeyError as e:\n",
    "                print(\"no skill set found\",e)\n",
    "\n",
    "    return skill_set\n",
    "\n",
    "\n",
    "print(get_skills(skill_dict,'opportunity'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_page(topic):\n",
    "    domain = \"https://en.wikipedia.org\"\n",
    "    html = urllib.request.urlopen(\"https://en.wikipedia.org/w/index.php?search=\"+topic.replace(' ','+')+\"&title=Special%3ASearch&go=Go\")\n",
    "    soup = BeautifulSoup(html, features=\"lxml\")\n",
    "    first_result = soup.find(attrs={\"data-serp-pos\": \"0\"})\n",
    "    if first_result is None:\n",
    "        print('page-found')\n",
    "        return soup\n",
    "    href = first_result.get('href')\n",
    "    print('opening first-result')\n",
    "    html = urllib.request.urlopen(domain+href)\n",
    "    soup = BeautifulSoup(html, features=\"lxml\")\n",
    "    return soup\n",
    "\n",
    "\n",
    "def get_first_para(topic):\n",
    "    soup = get_page(topic)\n",
    "    text_section = soup.find(attrs={'class': 'mw-parser-output'})\n",
    "    text = ''\n",
    "    for child in text_section.children:\n",
    "        # print('for tag', child.name, child)\n",
    "        try:\n",
    "            if child is not None:\n",
    "                if child.name == 'p':\n",
    "                    text += child.text.lower()\n",
    "                elif child.name == 'div' and 'toc' in child['class']:\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            print(\"exception\", e)\n",
    "    return text\n",
    "\n",
    "vo_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# cleaning we _have \n",
    "dore = []\n",
    "for x in we_have:\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    #First parameter is the replacement, second parameter is your input string\n",
    "    #regex.sub('', x)\n",
    "    dore.append(re.sub(\"[^a-zA-Z_ ]*\", \"\", x))\n",
    "\n",
    "for y in dore:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('tech2.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow(dore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #print(get_first_para('computer vision'))\n",
    "    for original in dore: \n",
    "        print(original)\n",
    "        w1=get_first_para(original)\n",
    "        w2=word_tokenize(w1)\n",
    "        \n",
    "        print(w1)\n",
    "\n",
    "        for word in w2:                                                                 \n",
    "            if word not in stop and word.__len__()>3 and word.isalpha():\n",
    "                w3 = get_skills(skill_dict, word)\n",
    "                for x in w3:\n",
    "                    vo_set.add(x)\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vo_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def load_skill_set2():\n",
    "\n",
    "    skill_dict = dict()\n",
    "    pick_file = open(\"final_skill_dict_2.pickle\", \"rb\")\n",
    "    skill_dict = pickle.load(pick_file)\n",
    "    pick_file.close()\n",
    "    return skill_dict\n",
    "\n",
    "\n",
    "def get_skill2(skill_dic,topic):\n",
    "    return skill_dic[ lemmatizer.lemmatize(topic.strip()) ]\n",
    "\n",
    "\n",
    "# skill_dict = make_skill_dict()\n",
    "skill_dict2 = load_skill_set2()\n",
    "\n",
    "print(get_skill2(skill_dict2,'procurement management'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(vo_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_set = set()\n",
    "for i in vo_set:\n",
    "    if i in skill_dict2:\n",
    "        new_set.add(get_skill2(skill_dict2,i))\n",
    "\n",
    "len(new_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------------NON- TECHNICAL SKILLS---------------')\n",
    "for word in new_set:\n",
    "    print(word)\n",
    "my_list2 = list(new_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('nontech2.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow(my_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying out reading just the extract for the technical skills\n",
    "import os\n",
    "files = [os.path.join('testing_2', fi) for fi in os.listdir('testing_2')]\n",
    "my_text = []\n",
    "from nltk.tokenize import word_tokenize\n",
    "for fil in files:\n",
    "    with open(fil) as fi:\n",
    "            line = fi.read()\n",
    "            temp= word_tokenize(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = list(temp)\n",
    "my_text =  [w.lower() for w in temp2 if not w.lower() in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_set = set()\n",
    "for q in my_text:\n",
    "    if q in skill_dict:\n",
    "        veu = get_skills(skill_dict,q)\n",
    "        for qw in veu:\n",
    "            q_set.add(qw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qw in q_set:\n",
    "    print(qw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(q_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_set = set()\n",
    "for i in q_set:\n",
    "    qq_set.add(get_skill2(skill_dict2,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for ele in qq_set:\n",
    "    temp = temp + (word_tokenize(ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict123 = {}\n",
    "my_final = {}\n",
    "my_final['others'] = set()\n",
    "print(temp)\n",
    "for i in temp:\n",
    "    if i in dict123:\n",
    "        dict123[i] = dict123[i]+1\n",
    "    else:\n",
    "        dict123[i] = 1\n",
    "for ele in qq_set:\n",
    "    w = word_tokenize(ele)\n",
    "    for i in w:\n",
    "        if dict123[i]>5:\n",
    "            if i in my_final:\n",
    "                my_final[i].add(ele)\n",
    "            else:\n",
    "                my_final[i] = set()\n",
    "                my_final[i].add(ele)\n",
    "        if dict123[i]<2:\n",
    "            my_final['others'].add(ele)\n",
    "len(qq_set)\n",
    "len(my_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------    Anupams dictionary  --------  ###\n",
    "\n",
    "\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# import pickle\n",
    "# import xlrd\n",
    "\n",
    "\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# # print(sheet.cell_value(0,0))\n",
    "\n",
    "\n",
    "# def make_skill_dict_final():\n",
    "\n",
    "#     file = (\"test_files/skills_anupam.xlsx\")\n",
    "\n",
    "#     wb = xlrd.open_workbook(file)\n",
    "#     sheet = wb.sheet_by_index(0)\n",
    "\n",
    "#     # print(len(lines))\n",
    "#     skill_dict = {}\n",
    "\n",
    "#     root_skill = ''\n",
    "#     for i in range(sheet.nrows):\n",
    "#         if sheet.cell_value(i,0) != '':\n",
    "#             root_skill = lemmatizer.lemmatize(sheet.cell_value(i, 0).strip().lower())\n",
    "\n",
    "#         for j in range(sheet.ncols):\n",
    "\n",
    "#             if sheet.cell_value(i, j) != '':\n",
    "#                 key = lemmatizer.lemmatize(sheet.cell_value(i, j).strip().lower())\n",
    "\n",
    "#                 if key in skill_dict:\n",
    "#                     skill_dict[key].add(root_skill)\n",
    "#                 else:\n",
    "#                     skill_dict[key] = {root_skill}\n",
    "\n",
    "#     print(\"printing dict.......\")\n",
    "#     for key in skill_dict:\n",
    "#         print(str(key).ljust(40) + str(skill_dict[key]).rjust(40))\n",
    "\n",
    "#     pick_file = open(\"anupam_skill_dict.pickle\",\"wb\")\n",
    "#     pickle.dump(skill_dict, pick_file)\n",
    "#     pick_file.close()\n",
    "\n",
    "#     return skill_dict\n",
    "\n",
    "\n",
    "# def load_skill_set_final():\n",
    "\n",
    "#     pick_file = open(\"anupam_skill_dict.pickle\", \"rb\")\n",
    "#     skill_dict = pickle.load(pick_file)\n",
    "#     pick_file.close()\n",
    "#     return skill_dict\n",
    "\n",
    "\n",
    "# def get_skill_final(skill_dic,topic):\n",
    "#     topic = lemmatizer.lemmatize(topic.strip().lower())\n",
    "#     if topic in skill_dic:\n",
    "#         return skill_dic[topic]\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "\n",
    "# # skill_dict = make_skill_dict()\n",
    "# skill_dict_final = load_skill_set()\n",
    "\n",
    "# print(get_skill_final(skill_dict_final,'motivate'))\n",
    "# # while True:\n",
    "# #     inp = input(\"topic:\")\n",
    "# #     print(get_skill(skill_dict,inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------Technical skills---------------')\n",
    "for zzz in dore:\n",
    "    print(zzz)\n",
    "print()\n",
    "print('----------------Technical skills---------------')\n",
    "print()\n",
    "\n",
    "for i in my_final:\n",
    "    \n",
    "    print('--------------------------------')\n",
    "    print('             --', i , '--')\n",
    "    print('---------------------------------')\n",
    "    for j in my_final[i]:\n",
    "        print(j, ',')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
