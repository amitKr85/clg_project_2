Risk adjustment of patient expenditures: A big data analytics approach&&&&&For healthcare applications, voluminous patient data contain rich and meaningful insights that can be revealed using advanced machine learning algorithms. However, the volume and velocity of such high dimensional data requires new big data analytics framework where traditional machine learning tools cannot be applied directly. In this paper, we introduce our proof-of-concept big data analytics framework for developing risk adjustment model of patient expenditures, which uses the “divide and conquer” strategy to exploit the big-yet-rich data to improve the model accuracy. We leverage the distributed computing platform, e.g., MapReduce, to implement advanced machine learning algorithms on our data set. In specific, random forest regression algorithm, which is suitable for high dimensional healthcare data, is applied to improve the accuracy of our predictive model. Our proof-of-concept framework demonstrates the effectiveness of predictive analytics using random forest algorithm as well as the efficiency of the distributed computing platform.&&&&&Data models,Computational modeling,Information management,Data handling,Data storage systems,Predictive models,Linear regression$$$$$Big Data,data analysis,distributed processing,divide and conquer methods,health care,learning (artificial intelligence),medical information systems,regression analysis$$$$$risk adjustment,patient expenditures,big data analytics approach,healthcare applications,patient data,machine learning algorithms,high dimensional data,machine learning tools,proof-of-concept big data analytics framework,divide and conquer strategy,big-yet-rich data,model accuracy,distributed computing platform,MapReduce,random forest regression algorithm,high dimensional healthcare data,predictive model,proof-of-concept framework,predictive analytics$$$$$Healthcare Big Data,Risk Adjustment,Distributed Computing,Random Forest,Patient Expenditure