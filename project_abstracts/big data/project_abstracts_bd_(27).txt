Fragmenting Big Data to Boost the Performance of MapReduce in Geographical Computing Contexts&&&&&The last few years have seen a growing demand of distributed Cloud infrastructures able to process big data generated by geographically scattered sources. A key challenge of this environment is how to manage big data across multiple heterogeneous datacenters interconnected through imbalanced network links. We designed a Hierarchical Hadoop Framework (H2F) where a top-level business logic smartly schedules bottom-level computing tasks capable of exploiting the potential of the MapReduce within each datacenter.In this work we discuss on the opportunity of fragmenting the big data into small pieces so that better workload configurations may be devised for the bottom-level tasks. Several case study experiments were run on a testbed where a software prototype of the designed framework was deployed. The test results are reported and discussed in the last part of the paper.&&&&&Big Data,Task analysis,Computational modeling,Data models,Distributed databases,Processor scheduling$$$$$Big Data,cloud computing,computer centres,data analysis,geographic information systems,parallel processing,scheduling$$$$$geographically scattered sources,multiple heterogeneous datacenters,imbalanced network links,Hierarchical Hadoop Framework,MapReduce,geographical computing,bottom-level computing task scheduling,top-level business logic,Big Data fragmentation,distributed cloud infrastructure,Big Data management,H2F,workload configurations,software prototype,Big Data processing$$$$$Big Data,MapReduce,Data fragmentation,Geographical computing environment,Hierarchical Hadoop